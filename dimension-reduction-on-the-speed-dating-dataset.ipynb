{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<h1 style=\"font-family:monospace\">1. Introduction</h1>\n<h2 style=\"font-family:monospace\">1.1 About the Dataset</h2>\n\n<div style = \"font-family:georgia, serif; font-size:17px\">\n\nThe dataset is retrived from <a href = \"https://www.kaggle.com/datasets/ulrikthygepedersen/speed-dating\">Ulrik Thyge Pedersen</a> on Kaggle. \n\nThis data was gathered from participants in experimental speed dating events from 2002-2004. During the events, the attendees would have a four-minute \"first date\" with every other participant of the opposite sex. At the end of their four minutes, participants were asked if they would like to see their date again. They were also asked to rate their date on six attributes: Attractiveness, Sincerity, Intelligence, Fun, Ambition, and Shared Interests. The dataset also includes questionnaire data gathered from participants at different points in the process. These fields include: demographics, dating habits, self-perception across key attributes, beliefs on what others find valuable in a mate, and lifestyle information.\n\n<table>\n    <tbody>\n        <tr><th>Variable</th><th>Description</th></tr>\n        <tr><td>gender</td><td> Gender of self</td></tr>\n        <tr><td>age</td><td> Age of self</td></tr>\n        <tr><td>age_o</td><td> Age of partner</td></tr>\n        <tr><td>d_age</td><td> Difference in age</td></tr>\n        <tr><td>d_age</td><td> Difference in age</td></tr>\n        <tr><td>race</td><td> Race of self</td></tr>\n        <tr><td>race_o</td><td> Race of partner</td></tr>\n        <tr><td>samerace</td><td> Whether the two persons have the same race or not.</td></tr>\n        <tr><td>importance_same_race</td><td> How important is it that partner is of same race?</td></tr>\n        <tr><td>importance_same_religion</td><td> How important is it that partner has same religion?</td></tr>\n        <tr><td>field</td><td> Field of study</td></tr>\n        <tr><td>pref_o_attractive</td><td> How important does partner rate attractiveness</td></tr>\n        <tr><td>pref_o_sinsere</td><td> How important does partner rate sincerity</td></tr>\n        <tr><td>pref_o_intelligence</td><td> How important does partner rate intelligence</td></tr>\n        <tr><td>pref_o_funny</td><td> How important does partner rate being funny</td></tr>\n        <tr><td>pref_o_ambitious</td><td> How important does partner rate ambition</td></tr>\n        <tr><td>pref_o_shared_interests</td><td> How important does partner rate having shared interests</td></tr>\n        <tr><td>attractive_o</td><td> Rating by partner (about me) at night of event on attractiveness</td></tr>\n        <tr><td>sincere_o</td><td> Rating by partner (about me) at night of event on sincerity</td></tr>\n        <tr><td>intelligence_o</td><td> Rating by partner (about me) at night of event on intelligence</td></tr>\n        <tr><td>funny_o</td><td> Rating by partner (about me) at night of event on being funny</td></tr>\n        <tr><td>ambitous_o</td><td> Rating by partner (about me) at night of event on being ambitious</td></tr>\n        <tr><td>shared_interests_o</td><td> Rating by partner (about me) at night of event on shared interest</td></tr>\n        <tr><td>attractive_important</td><td> What do you look for in a partner - attractiveness</td></tr>\n        <tr><td>sincere_important</td><td> What do you look for in a partner - sincerity</td></tr>\n        <tr><td>intellicence_important</td><td> What do you look for in a partner - intelligence</td></tr>\n        <tr><td>funny_important</td><td> What do you look for in a partner - being funny</td></tr>\n        <tr><td>ambtition_important</td><td> What do you look for in a partner - ambition</td></tr>\n        <tr><td>shared_interests_important</td><td> What do you look for in a partner - shared interests</td></tr>\n        <tr><td>attractive</td><td> Rate yourself - attractiveness</td></tr>\n        <tr><td>sincere</td><td> Rate yourself - sincerity</td></tr>\n        <tr><td>intelligence</td><td> Rate yourself - intelligence</td></tr>\n        <tr><td>funny</td><td> Rate yourself - being funny</td></tr>\n        <tr><td>ambition</td><td> Rate yourself - ambition</td></tr>\n        <tr><td>attractive_partner</td><td> Rate your partner - attractiveness</td></tr>\n        <tr><td>sincere_partner</td><td> Rate your partner - sincerity</td></tr>\n        <tr><td>intelligence_partner</td><td> Rate your partner - intelligence</td></tr>\n        <tr><td>funny_partner</td><td> Rate your partner - being funny</td></tr>\n        <tr><td>ambition_partner</td><td> Rate your partner - ambition</td></tr>\n        <tr><td>shared_interests_partner</td><td> Rate your partner - shared interests</td></tr>\n        <tr><td>sports</td><td> Your own interests [1-10]</td></tr>\n        <tr><td>interests_correlate</td>\n            <td> Correlation between participant’s and partner’s ratings of interests.</td></tr>\n        <tr><td>expected_happy_with_sd_people</td><td> How happy do you expect to be with the people you meet during the speed-dating event?</td></tr>\n        <tr><td>expected_num_interested_in_me</td><td> Out of the 20 people you will meet, how many do you expect will be interested in dating you?</td></tr>\n        <tr><td>expected_num_matches</td><td> How many matches do you expect to get?</td></tr>\n        <tr><td>like</td><td> Did you like your partner?</td></tr>\n        <tr><td>guess_prob_liked</td><td> How likely do you think it is that your partner likes you?</td></tr>\n        <tr><td>met</td><td> Have you met your partner before?</td></tr>\n        <tr><td>decision</td><td> Decision at night of event.</td></tr>\n        <tr><td>decision_o</td><td> Decision of partner at night of event.</td></tr>\n        <tr><td>match</td><td> Match (yes/no)</td></tr>\n    </tbody>\n</table>\n    \n <h2 style=\"font-family:monospace\">1.2 Purpose</h2>\n<ul>\n    <li>To clean the dataset and make it ready for a classification problem to determine whether the speed date is a match or not</li>\n<li>Conduct dimension reduction using various techniques to find the most important features to predict whether the date is a match or not</li>\n</ul>\n    \n<h2 style=\"font-family:monospace\">1.3 Further insight</h2>\n    \n<p style = \"font-family:georgia, serif; font-size:17px\">I have written an article explaining the steps followed in dimension reduction of the dataset and it can be found <a href =\"https://thesilentguru.com/dimension-reduction-in-python/\" >HERE</a></p>\n    \n    \n</div> ","metadata":{"_kg_hide-output":false}},{"cell_type":"markdown","source":"<h1 style=\"font-family:monospace\">2. Import libraries and read files</h1>","metadata":{}},{"cell_type":"code","source":"\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.decomposition import PCA\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder\nfrom sklearn.model_selection import train_test_split, cross_val_score\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.feature_extraction import DictVectorizer\n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.decomposition import PCA\nimport xgboost as xgb\n\nimport re\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-02-27T09:52:13.844597Z","iopub.execute_input":"2023-02-27T09:52:13.845043Z","iopub.status.idle":"2023-02-27T09:52:13.864646Z","shell.execute_reply.started":"2023-02-27T09:52:13.845008Z","shell.execute_reply":"2023-02-27T09:52:13.863046Z"},"trusted":true},"execution_count":184,"outputs":[{"name":"stdout","text":"/kaggle/input/speed-dating/speeddating.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"# Set default options\npd.set_option('display.max_columns', 150)\npd.set_option('display.max_rows', 130)","metadata":{"execution":{"iopub.status.busy":"2023-02-27T09:52:13.967164Z","iopub.execute_input":"2023-02-27T09:52:13.967597Z","iopub.status.idle":"2023-02-27T09:52:13.973966Z","shell.execute_reply.started":"2023-02-27T09:52:13.967564Z","shell.execute_reply":"2023-02-27T09:52:13.972622Z"},"trusted":true},"execution_count":185,"outputs":[]},{"cell_type":"code","source":"# Read dataset\ndating = pd.read_csv('/kaggle/input/speed-dating/speeddating.csv')","metadata":{"execution":{"iopub.status.busy":"2023-02-27T09:52:14.078646Z","iopub.execute_input":"2023-02-27T09:52:14.079087Z","iopub.status.idle":"2023-02-27T09:52:14.285437Z","shell.execute_reply.started":"2023-02-27T09:52:14.079053Z","shell.execute_reply":"2023-02-27T09:52:14.284023Z"},"trusted":true},"execution_count":186,"outputs":[]},{"cell_type":"markdown","source":"<h1 style=\"font-family:monospace\">3.Preview file</h1>","metadata":{}},{"cell_type":"code","source":"dating.head()","metadata":{"execution":{"iopub.status.busy":"2023-02-27T09:52:14.288317Z","iopub.execute_input":"2023-02-27T09:52:14.288734Z","iopub.status.idle":"2023-02-27T09:52:14.407539Z","shell.execute_reply.started":"2023-02-27T09:52:14.288700Z","shell.execute_reply":"2023-02-27T09:52:14.406270Z"},"trusted":true},"execution_count":187,"outputs":[{"execution_count":187,"output_type":"execute_result","data":{"text/plain":"  has_null  wave     gender   age  age_o  d_age   d_d_age  \\\n0      b''   1.0  b'female'  21.0   27.0    6.0  b'[4-6]'   \n1      b''   1.0  b'female'  21.0   22.0    1.0  b'[0-1]'   \n2      b''   1.0  b'female'  21.0   22.0    1.0  b'[0-1]'   \n3      b''   1.0  b'female'  21.0   23.0    2.0  b'[2-3]'   \n4      b''   1.0  b'female'  21.0   24.0    3.0  b'[2-3]'   \n\n                                       race  \\\n0  b'Asian/Pacific Islander/Asian-American'   \n1  b'Asian/Pacific Islander/Asian-American'   \n2  b'Asian/Pacific Islander/Asian-American'   \n3  b'Asian/Pacific Islander/Asian-American'   \n4  b'Asian/Pacific Islander/Asian-American'   \n\n                                     race_o samerace  importance_same_race  \\\n0            b'European/Caucasian-American'     b'0'                   2.0   \n1            b'European/Caucasian-American'     b'0'                   2.0   \n2  b'Asian/Pacific Islander/Asian-American'     b'1'                   2.0   \n3            b'European/Caucasian-American'     b'0'                   2.0   \n4               b'Latino/Hispanic American'     b'0'                   2.0   \n\n   importance_same_religion d_importance_same_race d_importance_same_religion  \\\n0                       4.0               b'[2-5]'                   b'[2-5]'   \n1                       4.0               b'[2-5]'                   b'[2-5]'   \n2                       4.0               b'[2-5]'                   b'[2-5]'   \n3                       4.0               b'[2-5]'                   b'[2-5]'   \n4                       4.0               b'[2-5]'                   b'[2-5]'   \n\n    field  pref_o_attractive  pref_o_sincere  pref_o_intelligence  \\\n0  b'Law'               35.0            20.0                 20.0   \n1  b'Law'               60.0             0.0                  0.0   \n2  b'Law'               19.0            18.0                 19.0   \n3  b'Law'               30.0             5.0                 15.0   \n4  b'Law'               30.0            10.0                 20.0   \n\n   pref_o_funny  pref_o_ambitious  pref_o_shared_interests  \\\n0          20.0               0.0                      5.0   \n1          40.0               0.0                      0.0   \n2          18.0              14.0                     12.0   \n3          40.0               5.0                      5.0   \n4          10.0              10.0                     20.0   \n\n  d_pref_o_attractive d_pref_o_sincere d_pref_o_intelligence d_pref_o_funny  \\\n0         b'[21-100]'       b'[16-20]'            b'[16-20]'     b'[16-20]'   \n1         b'[21-100]'        b'[0-15]'             b'[0-15]'    b'[21-100]'   \n2          b'[16-20]'       b'[16-20]'            b'[16-20]'     b'[16-20]'   \n3         b'[21-100]'        b'[0-15]'             b'[0-15]'    b'[21-100]'   \n4         b'[21-100]'        b'[0-15]'            b'[16-20]'      b'[0-15]'   \n\n  d_pref_o_ambitious d_pref_o_shared_interests  attractive_o  sinsere_o  \\\n0          b'[0-15]'                 b'[0-15]'           6.0        8.0   \n1          b'[0-15]'                 b'[0-15]'           7.0        8.0   \n2          b'[0-15]'                 b'[0-15]'          10.0       10.0   \n3          b'[0-15]'                 b'[0-15]'           7.0        8.0   \n4          b'[0-15]'                b'[16-20]'           8.0        7.0   \n\n   intelligence_o  funny_o  ambitous_o  shared_interests_o d_attractive_o  \\\n0             8.0      8.0         8.0                 6.0       b'[6-8]'   \n1            10.0      7.0         7.0                 5.0       b'[6-8]'   \n2            10.0     10.0        10.0                10.0      b'[9-10]'   \n3             9.0      8.0         9.0                 8.0       b'[6-8]'   \n4             9.0      6.0         9.0                 7.0       b'[6-8]'   \n\n  d_sinsere_o d_intelligence_o  d_funny_o d_ambitous_o d_shared_interests_o  \\\n0    b'[6-8]'         b'[6-8]'   b'[6-8]'     b'[6-8]'             b'[6-8]'   \n1    b'[6-8]'        b'[9-10]'   b'[6-8]'     b'[6-8]'             b'[0-5]'   \n2   b'[9-10]'        b'[9-10]'  b'[9-10]'    b'[9-10]'            b'[9-10]'   \n3    b'[6-8]'        b'[9-10]'   b'[6-8]'    b'[9-10]'             b'[6-8]'   \n4    b'[6-8]'        b'[9-10]'   b'[6-8]'    b'[9-10]'             b'[6-8]'   \n\n   attractive_important  sincere_important  intellicence_important  \\\n0                  15.0               20.0                    20.0   \n1                  15.0               20.0                    20.0   \n2                  15.0               20.0                    20.0   \n3                  15.0               20.0                    20.0   \n4                  15.0               20.0                    20.0   \n\n   funny_important  ambtition_important  shared_interests_important  \\\n0             15.0                 15.0                        15.0   \n1             15.0                 15.0                        15.0   \n2             15.0                 15.0                        15.0   \n3             15.0                 15.0                        15.0   \n4             15.0                 15.0                        15.0   \n\n  d_attractive_important d_sincere_important d_intellicence_important  \\\n0              b'[0-15]'          b'[16-20]'               b'[16-20]'   \n1              b'[0-15]'          b'[16-20]'               b'[16-20]'   \n2              b'[0-15]'          b'[16-20]'               b'[16-20]'   \n3              b'[0-15]'          b'[16-20]'               b'[16-20]'   \n4              b'[0-15]'          b'[16-20]'               b'[16-20]'   \n\n  d_funny_important d_ambtition_important d_shared_interests_important  \\\n0         b'[0-15]'             b'[0-15]'                    b'[0-15]'   \n1         b'[0-15]'             b'[0-15]'                    b'[0-15]'   \n2         b'[0-15]'             b'[0-15]'                    b'[0-15]'   \n3         b'[0-15]'             b'[0-15]'                    b'[0-15]'   \n4         b'[0-15]'             b'[0-15]'                    b'[0-15]'   \n\n   attractive  sincere  intelligence  funny  ambition d_attractive d_sincere  \\\n0         6.0      8.0           8.0    8.0       7.0     b'[6-8]'  b'[6-8]'   \n1         6.0      8.0           8.0    8.0       7.0     b'[6-8]'  b'[6-8]'   \n2         6.0      8.0           8.0    8.0       7.0     b'[6-8]'  b'[6-8]'   \n3         6.0      8.0           8.0    8.0       7.0     b'[6-8]'  b'[6-8]'   \n4         6.0      8.0           8.0    8.0       7.0     b'[6-8]'  b'[6-8]'   \n\n  d_intelligence   d_funny d_ambition  attractive_partner  sincere_partner  \\\n0       b'[6-8]'  b'[6-8]'   b'[6-8]'                 6.0              9.0   \n1       b'[6-8]'  b'[6-8]'   b'[6-8]'                 7.0              8.0   \n2       b'[6-8]'  b'[6-8]'   b'[6-8]'                 5.0              8.0   \n3       b'[6-8]'  b'[6-8]'   b'[6-8]'                 7.0              6.0   \n4       b'[6-8]'  b'[6-8]'   b'[6-8]'                 5.0              6.0   \n\n   intelligence_partner  funny_partner  ambition_partner  \\\n0                   7.0            7.0               6.0   \n1                   7.0            8.0               5.0   \n2                   9.0            8.0               5.0   \n3                   8.0            7.0               6.0   \n4                   7.0            7.0               6.0   \n\n   shared_interests_partner d_attractive_partner d_sincere_partner  \\\n0                       5.0             b'[6-8]'         b'[9-10]'   \n1                       6.0             b'[6-8]'          b'[6-8]'   \n2                       7.0             b'[0-5]'          b'[6-8]'   \n3                       8.0             b'[6-8]'          b'[6-8]'   \n4                       6.0             b'[0-5]'          b'[6-8]'   \n\n  d_intelligence_partner d_funny_partner d_ambition_partner  \\\n0               b'[6-8]'        b'[6-8]'           b'[6-8]'   \n1               b'[6-8]'        b'[6-8]'           b'[0-5]'   \n2              b'[9-10]'        b'[6-8]'           b'[0-5]'   \n3               b'[6-8]'        b'[6-8]'           b'[6-8]'   \n4               b'[6-8]'        b'[6-8]'           b'[6-8]'   \n\n  d_shared_interests_partner  sports  tvsports  exercise  dining  museums  \\\n0                   b'[0-5]'     9.0       2.0       8.0     9.0      1.0   \n1                   b'[6-8]'     9.0       2.0       8.0     9.0      1.0   \n2                   b'[6-8]'     9.0       2.0       8.0     9.0      1.0   \n3                   b'[6-8]'     9.0       2.0       8.0     9.0      1.0   \n4                   b'[6-8]'     9.0       2.0       8.0     9.0      1.0   \n\n   art  hiking  gaming  clubbing  reading   tv  theater  movies  concerts  \\\n0  1.0     5.0     1.0       5.0      6.0  9.0      1.0    10.0      10.0   \n1  1.0     5.0     1.0       5.0      6.0  9.0      1.0    10.0      10.0   \n2  1.0     5.0     1.0       5.0      6.0  9.0      1.0    10.0      10.0   \n3  1.0     5.0     1.0       5.0      6.0  9.0      1.0    10.0      10.0   \n4  1.0     5.0     1.0       5.0      6.0  9.0      1.0    10.0      10.0   \n\n   music  shopping  yoga   d_sports d_tvsports d_exercise   d_dining  \\\n0    9.0       8.0   1.0  b'[9-10]'   b'[0-5]'   b'[6-8]'  b'[9-10]'   \n1    9.0       8.0   1.0  b'[9-10]'   b'[0-5]'   b'[6-8]'  b'[9-10]'   \n2    9.0       8.0   1.0  b'[9-10]'   b'[0-5]'   b'[6-8]'  b'[9-10]'   \n3    9.0       8.0   1.0  b'[9-10]'   b'[0-5]'   b'[6-8]'  b'[9-10]'   \n4    9.0       8.0   1.0  b'[9-10]'   b'[0-5]'   b'[6-8]'  b'[9-10]'   \n\n  d_museums     d_art  d_hiking  d_gaming d_clubbing d_reading       d_tv  \\\n0  b'[0-5]'  b'[0-5]'  b'[0-5]'  b'[0-5]'   b'[0-5]'  b'[6-8]'  b'[9-10]'   \n1  b'[0-5]'  b'[0-5]'  b'[0-5]'  b'[0-5]'   b'[0-5]'  b'[6-8]'  b'[9-10]'   \n2  b'[0-5]'  b'[0-5]'  b'[0-5]'  b'[0-5]'   b'[0-5]'  b'[6-8]'  b'[9-10]'   \n3  b'[0-5]'  b'[0-5]'  b'[0-5]'  b'[0-5]'   b'[0-5]'  b'[6-8]'  b'[9-10]'   \n4  b'[0-5]'  b'[0-5]'  b'[0-5]'  b'[0-5]'   b'[0-5]'  b'[6-8]'  b'[9-10]'   \n\n  d_theater   d_movies d_concerts    d_music d_shopping    d_yoga  \\\n0  b'[0-5]'  b'[9-10]'  b'[9-10]'  b'[9-10]'   b'[6-8]'  b'[0-5]'   \n1  b'[0-5]'  b'[9-10]'  b'[9-10]'  b'[9-10]'   b'[6-8]'  b'[0-5]'   \n2  b'[0-5]'  b'[9-10]'  b'[9-10]'  b'[9-10]'   b'[6-8]'  b'[0-5]'   \n3  b'[0-5]'  b'[9-10]'  b'[9-10]'  b'[9-10]'   b'[6-8]'  b'[0-5]'   \n4  b'[0-5]'  b'[9-10]'  b'[9-10]'  b'[9-10]'   b'[6-8]'  b'[0-5]'   \n\n   interests_correlate d_interests_correlate  expected_happy_with_sd_people  \\\n0                 0.14           b'[0-0.33]'                            3.0   \n1                 0.54           b'[0.33-1]'                            3.0   \n2                 0.16           b'[0-0.33]'                            3.0   \n3                 0.61           b'[0.33-1]'                            3.0   \n4                 0.21           b'[0-0.33]'                            3.0   \n\n   expected_num_interested_in_me  expected_num_matches  \\\n0                            2.0                   4.0   \n1                            2.0                   4.0   \n2                            2.0                   4.0   \n3                            2.0                   4.0   \n4                            2.0                   4.0   \n\n  d_expected_happy_with_sd_people d_expected_num_interested_in_me  \\\n0                        b'[0-4]'                        b'[0-3]'   \n1                        b'[0-4]'                        b'[0-3]'   \n2                        b'[0-4]'                        b'[0-3]'   \n3                        b'[0-4]'                        b'[0-3]'   \n4                        b'[0-4]'                        b'[0-3]'   \n\n  d_expected_num_matches  like  guess_prob_liked    d_like d_guess_prob_liked  \\\n0               b'[3-5]'   7.0               6.0  b'[6-8]'           b'[5-6]'   \n1               b'[3-5]'   7.0               5.0  b'[6-8]'           b'[5-6]'   \n2               b'[3-5]'   7.0               NaN  b'[6-8]'           b'[0-4]'   \n3               b'[3-5]'   7.0               6.0  b'[6-8]'           b'[5-6]'   \n4               b'[3-5]'   6.0               6.0  b'[6-8]'           b'[5-6]'   \n\n   met decision decision_o match  \n0  0.0     b'1'       b'0'  b'0'  \n1  1.0     b'1'       b'0'  b'0'  \n2  1.0     b'1'       b'1'  b'1'  \n3  0.0     b'1'       b'1'  b'1'  \n4  0.0     b'1'       b'1'  b'1'  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>has_null</th>\n      <th>wave</th>\n      <th>gender</th>\n      <th>age</th>\n      <th>age_o</th>\n      <th>d_age</th>\n      <th>d_d_age</th>\n      <th>race</th>\n      <th>race_o</th>\n      <th>samerace</th>\n      <th>importance_same_race</th>\n      <th>importance_same_religion</th>\n      <th>d_importance_same_race</th>\n      <th>d_importance_same_religion</th>\n      <th>field</th>\n      <th>pref_o_attractive</th>\n      <th>pref_o_sincere</th>\n      <th>pref_o_intelligence</th>\n      <th>pref_o_funny</th>\n      <th>pref_o_ambitious</th>\n      <th>pref_o_shared_interests</th>\n      <th>d_pref_o_attractive</th>\n      <th>d_pref_o_sincere</th>\n      <th>d_pref_o_intelligence</th>\n      <th>d_pref_o_funny</th>\n      <th>d_pref_o_ambitious</th>\n      <th>d_pref_o_shared_interests</th>\n      <th>attractive_o</th>\n      <th>sinsere_o</th>\n      <th>intelligence_o</th>\n      <th>funny_o</th>\n      <th>ambitous_o</th>\n      <th>shared_interests_o</th>\n      <th>d_attractive_o</th>\n      <th>d_sinsere_o</th>\n      <th>d_intelligence_o</th>\n      <th>d_funny_o</th>\n      <th>d_ambitous_o</th>\n      <th>d_shared_interests_o</th>\n      <th>attractive_important</th>\n      <th>sincere_important</th>\n      <th>intellicence_important</th>\n      <th>funny_important</th>\n      <th>ambtition_important</th>\n      <th>shared_interests_important</th>\n      <th>d_attractive_important</th>\n      <th>d_sincere_important</th>\n      <th>d_intellicence_important</th>\n      <th>d_funny_important</th>\n      <th>d_ambtition_important</th>\n      <th>d_shared_interests_important</th>\n      <th>attractive</th>\n      <th>sincere</th>\n      <th>intelligence</th>\n      <th>funny</th>\n      <th>ambition</th>\n      <th>d_attractive</th>\n      <th>d_sincere</th>\n      <th>d_intelligence</th>\n      <th>d_funny</th>\n      <th>d_ambition</th>\n      <th>attractive_partner</th>\n      <th>sincere_partner</th>\n      <th>intelligence_partner</th>\n      <th>funny_partner</th>\n      <th>ambition_partner</th>\n      <th>shared_interests_partner</th>\n      <th>d_attractive_partner</th>\n      <th>d_sincere_partner</th>\n      <th>d_intelligence_partner</th>\n      <th>d_funny_partner</th>\n      <th>d_ambition_partner</th>\n      <th>d_shared_interests_partner</th>\n      <th>sports</th>\n      <th>tvsports</th>\n      <th>exercise</th>\n      <th>dining</th>\n      <th>museums</th>\n      <th>art</th>\n      <th>hiking</th>\n      <th>gaming</th>\n      <th>clubbing</th>\n      <th>reading</th>\n      <th>tv</th>\n      <th>theater</th>\n      <th>movies</th>\n      <th>concerts</th>\n      <th>music</th>\n      <th>shopping</th>\n      <th>yoga</th>\n      <th>d_sports</th>\n      <th>d_tvsports</th>\n      <th>d_exercise</th>\n      <th>d_dining</th>\n      <th>d_museums</th>\n      <th>d_art</th>\n      <th>d_hiking</th>\n      <th>d_gaming</th>\n      <th>d_clubbing</th>\n      <th>d_reading</th>\n      <th>d_tv</th>\n      <th>d_theater</th>\n      <th>d_movies</th>\n      <th>d_concerts</th>\n      <th>d_music</th>\n      <th>d_shopping</th>\n      <th>d_yoga</th>\n      <th>interests_correlate</th>\n      <th>d_interests_correlate</th>\n      <th>expected_happy_with_sd_people</th>\n      <th>expected_num_interested_in_me</th>\n      <th>expected_num_matches</th>\n      <th>d_expected_happy_with_sd_people</th>\n      <th>d_expected_num_interested_in_me</th>\n      <th>d_expected_num_matches</th>\n      <th>like</th>\n      <th>guess_prob_liked</th>\n      <th>d_like</th>\n      <th>d_guess_prob_liked</th>\n      <th>met</th>\n      <th>decision</th>\n      <th>decision_o</th>\n      <th>match</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>b''</td>\n      <td>1.0</td>\n      <td>b'female'</td>\n      <td>21.0</td>\n      <td>27.0</td>\n      <td>6.0</td>\n      <td>b'[4-6]'</td>\n      <td>b'Asian/Pacific Islander/Asian-American'</td>\n      <td>b'European/Caucasian-American'</td>\n      <td>b'0'</td>\n      <td>2.0</td>\n      <td>4.0</td>\n      <td>b'[2-5]'</td>\n      <td>b'[2-5]'</td>\n      <td>b'Law'</td>\n      <td>35.0</td>\n      <td>20.0</td>\n      <td>20.0</td>\n      <td>20.0</td>\n      <td>0.0</td>\n      <td>5.0</td>\n      <td>b'[21-100]'</td>\n      <td>b'[16-20]'</td>\n      <td>b'[16-20]'</td>\n      <td>b'[16-20]'</td>\n      <td>b'[0-15]'</td>\n      <td>b'[0-15]'</td>\n      <td>6.0</td>\n      <td>8.0</td>\n      <td>8.0</td>\n      <td>8.0</td>\n      <td>8.0</td>\n      <td>6.0</td>\n      <td>b'[6-8]'</td>\n      <td>b'[6-8]'</td>\n      <td>b'[6-8]'</td>\n      <td>b'[6-8]'</td>\n      <td>b'[6-8]'</td>\n      <td>b'[6-8]'</td>\n      <td>15.0</td>\n      <td>20.0</td>\n      <td>20.0</td>\n      <td>15.0</td>\n      <td>15.0</td>\n      <td>15.0</td>\n      <td>b'[0-15]'</td>\n      <td>b'[16-20]'</td>\n      <td>b'[16-20]'</td>\n      <td>b'[0-15]'</td>\n      <td>b'[0-15]'</td>\n      <td>b'[0-15]'</td>\n      <td>6.0</td>\n      <td>8.0</td>\n      <td>8.0</td>\n      <td>8.0</td>\n      <td>7.0</td>\n      <td>b'[6-8]'</td>\n      <td>b'[6-8]'</td>\n      <td>b'[6-8]'</td>\n      <td>b'[6-8]'</td>\n      <td>b'[6-8]'</td>\n      <td>6.0</td>\n      <td>9.0</td>\n      <td>7.0</td>\n      <td>7.0</td>\n      <td>6.0</td>\n      <td>5.0</td>\n      <td>b'[6-8]'</td>\n      <td>b'[9-10]'</td>\n      <td>b'[6-8]'</td>\n      <td>b'[6-8]'</td>\n      <td>b'[6-8]'</td>\n      <td>b'[0-5]'</td>\n      <td>9.0</td>\n      <td>2.0</td>\n      <td>8.0</td>\n      <td>9.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>5.0</td>\n      <td>1.0</td>\n      <td>5.0</td>\n      <td>6.0</td>\n      <td>9.0</td>\n      <td>1.0</td>\n      <td>10.0</td>\n      <td>10.0</td>\n      <td>9.0</td>\n      <td>8.0</td>\n      <td>1.0</td>\n      <td>b'[9-10]'</td>\n      <td>b'[0-5]'</td>\n      <td>b'[6-8]'</td>\n      <td>b'[9-10]'</td>\n      <td>b'[0-5]'</td>\n      <td>b'[0-5]'</td>\n      <td>b'[0-5]'</td>\n      <td>b'[0-5]'</td>\n      <td>b'[0-5]'</td>\n      <td>b'[6-8]'</td>\n      <td>b'[9-10]'</td>\n      <td>b'[0-5]'</td>\n      <td>b'[9-10]'</td>\n      <td>b'[9-10]'</td>\n      <td>b'[9-10]'</td>\n      <td>b'[6-8]'</td>\n      <td>b'[0-5]'</td>\n      <td>0.14</td>\n      <td>b'[0-0.33]'</td>\n      <td>3.0</td>\n      <td>2.0</td>\n      <td>4.0</td>\n      <td>b'[0-4]'</td>\n      <td>b'[0-3]'</td>\n      <td>b'[3-5]'</td>\n      <td>7.0</td>\n      <td>6.0</td>\n      <td>b'[6-8]'</td>\n      <td>b'[5-6]'</td>\n      <td>0.0</td>\n      <td>b'1'</td>\n      <td>b'0'</td>\n      <td>b'0'</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>b''</td>\n      <td>1.0</td>\n      <td>b'female'</td>\n      <td>21.0</td>\n      <td>22.0</td>\n      <td>1.0</td>\n      <td>b'[0-1]'</td>\n      <td>b'Asian/Pacific Islander/Asian-American'</td>\n      <td>b'European/Caucasian-American'</td>\n      <td>b'0'</td>\n      <td>2.0</td>\n      <td>4.0</td>\n      <td>b'[2-5]'</td>\n      <td>b'[2-5]'</td>\n      <td>b'Law'</td>\n      <td>60.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>40.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>b'[21-100]'</td>\n      <td>b'[0-15]'</td>\n      <td>b'[0-15]'</td>\n      <td>b'[21-100]'</td>\n      <td>b'[0-15]'</td>\n      <td>b'[0-15]'</td>\n      <td>7.0</td>\n      <td>8.0</td>\n      <td>10.0</td>\n      <td>7.0</td>\n      <td>7.0</td>\n      <td>5.0</td>\n      <td>b'[6-8]'</td>\n      <td>b'[6-8]'</td>\n      <td>b'[9-10]'</td>\n      <td>b'[6-8]'</td>\n      <td>b'[6-8]'</td>\n      <td>b'[0-5]'</td>\n      <td>15.0</td>\n      <td>20.0</td>\n      <td>20.0</td>\n      <td>15.0</td>\n      <td>15.0</td>\n      <td>15.0</td>\n      <td>b'[0-15]'</td>\n      <td>b'[16-20]'</td>\n      <td>b'[16-20]'</td>\n      <td>b'[0-15]'</td>\n      <td>b'[0-15]'</td>\n      <td>b'[0-15]'</td>\n      <td>6.0</td>\n      <td>8.0</td>\n      <td>8.0</td>\n      <td>8.0</td>\n      <td>7.0</td>\n      <td>b'[6-8]'</td>\n      <td>b'[6-8]'</td>\n      <td>b'[6-8]'</td>\n      <td>b'[6-8]'</td>\n      <td>b'[6-8]'</td>\n      <td>7.0</td>\n      <td>8.0</td>\n      <td>7.0</td>\n      <td>8.0</td>\n      <td>5.0</td>\n      <td>6.0</td>\n      <td>b'[6-8]'</td>\n      <td>b'[6-8]'</td>\n      <td>b'[6-8]'</td>\n      <td>b'[6-8]'</td>\n      <td>b'[0-5]'</td>\n      <td>b'[6-8]'</td>\n      <td>9.0</td>\n      <td>2.0</td>\n      <td>8.0</td>\n      <td>9.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>5.0</td>\n      <td>1.0</td>\n      <td>5.0</td>\n      <td>6.0</td>\n      <td>9.0</td>\n      <td>1.0</td>\n      <td>10.0</td>\n      <td>10.0</td>\n      <td>9.0</td>\n      <td>8.0</td>\n      <td>1.0</td>\n      <td>b'[9-10]'</td>\n      <td>b'[0-5]'</td>\n      <td>b'[6-8]'</td>\n      <td>b'[9-10]'</td>\n      <td>b'[0-5]'</td>\n      <td>b'[0-5]'</td>\n      <td>b'[0-5]'</td>\n      <td>b'[0-5]'</td>\n      <td>b'[0-5]'</td>\n      <td>b'[6-8]'</td>\n      <td>b'[9-10]'</td>\n      <td>b'[0-5]'</td>\n      <td>b'[9-10]'</td>\n      <td>b'[9-10]'</td>\n      <td>b'[9-10]'</td>\n      <td>b'[6-8]'</td>\n      <td>b'[0-5]'</td>\n      <td>0.54</td>\n      <td>b'[0.33-1]'</td>\n      <td>3.0</td>\n      <td>2.0</td>\n      <td>4.0</td>\n      <td>b'[0-4]'</td>\n      <td>b'[0-3]'</td>\n      <td>b'[3-5]'</td>\n      <td>7.0</td>\n      <td>5.0</td>\n      <td>b'[6-8]'</td>\n      <td>b'[5-6]'</td>\n      <td>1.0</td>\n      <td>b'1'</td>\n      <td>b'0'</td>\n      <td>b'0'</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>b''</td>\n      <td>1.0</td>\n      <td>b'female'</td>\n      <td>21.0</td>\n      <td>22.0</td>\n      <td>1.0</td>\n      <td>b'[0-1]'</td>\n      <td>b'Asian/Pacific Islander/Asian-American'</td>\n      <td>b'Asian/Pacific Islander/Asian-American'</td>\n      <td>b'1'</td>\n      <td>2.0</td>\n      <td>4.0</td>\n      <td>b'[2-5]'</td>\n      <td>b'[2-5]'</td>\n      <td>b'Law'</td>\n      <td>19.0</td>\n      <td>18.0</td>\n      <td>19.0</td>\n      <td>18.0</td>\n      <td>14.0</td>\n      <td>12.0</td>\n      <td>b'[16-20]'</td>\n      <td>b'[16-20]'</td>\n      <td>b'[16-20]'</td>\n      <td>b'[16-20]'</td>\n      <td>b'[0-15]'</td>\n      <td>b'[0-15]'</td>\n      <td>10.0</td>\n      <td>10.0</td>\n      <td>10.0</td>\n      <td>10.0</td>\n      <td>10.0</td>\n      <td>10.0</td>\n      <td>b'[9-10]'</td>\n      <td>b'[9-10]'</td>\n      <td>b'[9-10]'</td>\n      <td>b'[9-10]'</td>\n      <td>b'[9-10]'</td>\n      <td>b'[9-10]'</td>\n      <td>15.0</td>\n      <td>20.0</td>\n      <td>20.0</td>\n      <td>15.0</td>\n      <td>15.0</td>\n      <td>15.0</td>\n      <td>b'[0-15]'</td>\n      <td>b'[16-20]'</td>\n      <td>b'[16-20]'</td>\n      <td>b'[0-15]'</td>\n      <td>b'[0-15]'</td>\n      <td>b'[0-15]'</td>\n      <td>6.0</td>\n      <td>8.0</td>\n      <td>8.0</td>\n      <td>8.0</td>\n      <td>7.0</td>\n      <td>b'[6-8]'</td>\n      <td>b'[6-8]'</td>\n      <td>b'[6-8]'</td>\n      <td>b'[6-8]'</td>\n      <td>b'[6-8]'</td>\n      <td>5.0</td>\n      <td>8.0</td>\n      <td>9.0</td>\n      <td>8.0</td>\n      <td>5.0</td>\n      <td>7.0</td>\n      <td>b'[0-5]'</td>\n      <td>b'[6-8]'</td>\n      <td>b'[9-10]'</td>\n      <td>b'[6-8]'</td>\n      <td>b'[0-5]'</td>\n      <td>b'[6-8]'</td>\n      <td>9.0</td>\n      <td>2.0</td>\n      <td>8.0</td>\n      <td>9.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>5.0</td>\n      <td>1.0</td>\n      <td>5.0</td>\n      <td>6.0</td>\n      <td>9.0</td>\n      <td>1.0</td>\n      <td>10.0</td>\n      <td>10.0</td>\n      <td>9.0</td>\n      <td>8.0</td>\n      <td>1.0</td>\n      <td>b'[9-10]'</td>\n      <td>b'[0-5]'</td>\n      <td>b'[6-8]'</td>\n      <td>b'[9-10]'</td>\n      <td>b'[0-5]'</td>\n      <td>b'[0-5]'</td>\n      <td>b'[0-5]'</td>\n      <td>b'[0-5]'</td>\n      <td>b'[0-5]'</td>\n      <td>b'[6-8]'</td>\n      <td>b'[9-10]'</td>\n      <td>b'[0-5]'</td>\n      <td>b'[9-10]'</td>\n      <td>b'[9-10]'</td>\n      <td>b'[9-10]'</td>\n      <td>b'[6-8]'</td>\n      <td>b'[0-5]'</td>\n      <td>0.16</td>\n      <td>b'[0-0.33]'</td>\n      <td>3.0</td>\n      <td>2.0</td>\n      <td>4.0</td>\n      <td>b'[0-4]'</td>\n      <td>b'[0-3]'</td>\n      <td>b'[3-5]'</td>\n      <td>7.0</td>\n      <td>NaN</td>\n      <td>b'[6-8]'</td>\n      <td>b'[0-4]'</td>\n      <td>1.0</td>\n      <td>b'1'</td>\n      <td>b'1'</td>\n      <td>b'1'</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>b''</td>\n      <td>1.0</td>\n      <td>b'female'</td>\n      <td>21.0</td>\n      <td>23.0</td>\n      <td>2.0</td>\n      <td>b'[2-3]'</td>\n      <td>b'Asian/Pacific Islander/Asian-American'</td>\n      <td>b'European/Caucasian-American'</td>\n      <td>b'0'</td>\n      <td>2.0</td>\n      <td>4.0</td>\n      <td>b'[2-5]'</td>\n      <td>b'[2-5]'</td>\n      <td>b'Law'</td>\n      <td>30.0</td>\n      <td>5.0</td>\n      <td>15.0</td>\n      <td>40.0</td>\n      <td>5.0</td>\n      <td>5.0</td>\n      <td>b'[21-100]'</td>\n      <td>b'[0-15]'</td>\n      <td>b'[0-15]'</td>\n      <td>b'[21-100]'</td>\n      <td>b'[0-15]'</td>\n      <td>b'[0-15]'</td>\n      <td>7.0</td>\n      <td>8.0</td>\n      <td>9.0</td>\n      <td>8.0</td>\n      <td>9.0</td>\n      <td>8.0</td>\n      <td>b'[6-8]'</td>\n      <td>b'[6-8]'</td>\n      <td>b'[9-10]'</td>\n      <td>b'[6-8]'</td>\n      <td>b'[9-10]'</td>\n      <td>b'[6-8]'</td>\n      <td>15.0</td>\n      <td>20.0</td>\n      <td>20.0</td>\n      <td>15.0</td>\n      <td>15.0</td>\n      <td>15.0</td>\n      <td>b'[0-15]'</td>\n      <td>b'[16-20]'</td>\n      <td>b'[16-20]'</td>\n      <td>b'[0-15]'</td>\n      <td>b'[0-15]'</td>\n      <td>b'[0-15]'</td>\n      <td>6.0</td>\n      <td>8.0</td>\n      <td>8.0</td>\n      <td>8.0</td>\n      <td>7.0</td>\n      <td>b'[6-8]'</td>\n      <td>b'[6-8]'</td>\n      <td>b'[6-8]'</td>\n      <td>b'[6-8]'</td>\n      <td>b'[6-8]'</td>\n      <td>7.0</td>\n      <td>6.0</td>\n      <td>8.0</td>\n      <td>7.0</td>\n      <td>6.0</td>\n      <td>8.0</td>\n      <td>b'[6-8]'</td>\n      <td>b'[6-8]'</td>\n      <td>b'[6-8]'</td>\n      <td>b'[6-8]'</td>\n      <td>b'[6-8]'</td>\n      <td>b'[6-8]'</td>\n      <td>9.0</td>\n      <td>2.0</td>\n      <td>8.0</td>\n      <td>9.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>5.0</td>\n      <td>1.0</td>\n      <td>5.0</td>\n      <td>6.0</td>\n      <td>9.0</td>\n      <td>1.0</td>\n      <td>10.0</td>\n      <td>10.0</td>\n      <td>9.0</td>\n      <td>8.0</td>\n      <td>1.0</td>\n      <td>b'[9-10]'</td>\n      <td>b'[0-5]'</td>\n      <td>b'[6-8]'</td>\n      <td>b'[9-10]'</td>\n      <td>b'[0-5]'</td>\n      <td>b'[0-5]'</td>\n      <td>b'[0-5]'</td>\n      <td>b'[0-5]'</td>\n      <td>b'[0-5]'</td>\n      <td>b'[6-8]'</td>\n      <td>b'[9-10]'</td>\n      <td>b'[0-5]'</td>\n      <td>b'[9-10]'</td>\n      <td>b'[9-10]'</td>\n      <td>b'[9-10]'</td>\n      <td>b'[6-8]'</td>\n      <td>b'[0-5]'</td>\n      <td>0.61</td>\n      <td>b'[0.33-1]'</td>\n      <td>3.0</td>\n      <td>2.0</td>\n      <td>4.0</td>\n      <td>b'[0-4]'</td>\n      <td>b'[0-3]'</td>\n      <td>b'[3-5]'</td>\n      <td>7.0</td>\n      <td>6.0</td>\n      <td>b'[6-8]'</td>\n      <td>b'[5-6]'</td>\n      <td>0.0</td>\n      <td>b'1'</td>\n      <td>b'1'</td>\n      <td>b'1'</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>b''</td>\n      <td>1.0</td>\n      <td>b'female'</td>\n      <td>21.0</td>\n      <td>24.0</td>\n      <td>3.0</td>\n      <td>b'[2-3]'</td>\n      <td>b'Asian/Pacific Islander/Asian-American'</td>\n      <td>b'Latino/Hispanic American'</td>\n      <td>b'0'</td>\n      <td>2.0</td>\n      <td>4.0</td>\n      <td>b'[2-5]'</td>\n      <td>b'[2-5]'</td>\n      <td>b'Law'</td>\n      <td>30.0</td>\n      <td>10.0</td>\n      <td>20.0</td>\n      <td>10.0</td>\n      <td>10.0</td>\n      <td>20.0</td>\n      <td>b'[21-100]'</td>\n      <td>b'[0-15]'</td>\n      <td>b'[16-20]'</td>\n      <td>b'[0-15]'</td>\n      <td>b'[0-15]'</td>\n      <td>b'[16-20]'</td>\n      <td>8.0</td>\n      <td>7.0</td>\n      <td>9.0</td>\n      <td>6.0</td>\n      <td>9.0</td>\n      <td>7.0</td>\n      <td>b'[6-8]'</td>\n      <td>b'[6-8]'</td>\n      <td>b'[9-10]'</td>\n      <td>b'[6-8]'</td>\n      <td>b'[9-10]'</td>\n      <td>b'[6-8]'</td>\n      <td>15.0</td>\n      <td>20.0</td>\n      <td>20.0</td>\n      <td>15.0</td>\n      <td>15.0</td>\n      <td>15.0</td>\n      <td>b'[0-15]'</td>\n      <td>b'[16-20]'</td>\n      <td>b'[16-20]'</td>\n      <td>b'[0-15]'</td>\n      <td>b'[0-15]'</td>\n      <td>b'[0-15]'</td>\n      <td>6.0</td>\n      <td>8.0</td>\n      <td>8.0</td>\n      <td>8.0</td>\n      <td>7.0</td>\n      <td>b'[6-8]'</td>\n      <td>b'[6-8]'</td>\n      <td>b'[6-8]'</td>\n      <td>b'[6-8]'</td>\n      <td>b'[6-8]'</td>\n      <td>5.0</td>\n      <td>6.0</td>\n      <td>7.0</td>\n      <td>7.0</td>\n      <td>6.0</td>\n      <td>6.0</td>\n      <td>b'[0-5]'</td>\n      <td>b'[6-8]'</td>\n      <td>b'[6-8]'</td>\n      <td>b'[6-8]'</td>\n      <td>b'[6-8]'</td>\n      <td>b'[6-8]'</td>\n      <td>9.0</td>\n      <td>2.0</td>\n      <td>8.0</td>\n      <td>9.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>5.0</td>\n      <td>1.0</td>\n      <td>5.0</td>\n      <td>6.0</td>\n      <td>9.0</td>\n      <td>1.0</td>\n      <td>10.0</td>\n      <td>10.0</td>\n      <td>9.0</td>\n      <td>8.0</td>\n      <td>1.0</td>\n      <td>b'[9-10]'</td>\n      <td>b'[0-5]'</td>\n      <td>b'[6-8]'</td>\n      <td>b'[9-10]'</td>\n      <td>b'[0-5]'</td>\n      <td>b'[0-5]'</td>\n      <td>b'[0-5]'</td>\n      <td>b'[0-5]'</td>\n      <td>b'[0-5]'</td>\n      <td>b'[6-8]'</td>\n      <td>b'[9-10]'</td>\n      <td>b'[0-5]'</td>\n      <td>b'[9-10]'</td>\n      <td>b'[9-10]'</td>\n      <td>b'[9-10]'</td>\n      <td>b'[6-8]'</td>\n      <td>b'[0-5]'</td>\n      <td>0.21</td>\n      <td>b'[0-0.33]'</td>\n      <td>3.0</td>\n      <td>2.0</td>\n      <td>4.0</td>\n      <td>b'[0-4]'</td>\n      <td>b'[0-3]'</td>\n      <td>b'[3-5]'</td>\n      <td>6.0</td>\n      <td>6.0</td>\n      <td>b'[6-8]'</td>\n      <td>b'[5-6]'</td>\n      <td>0.0</td>\n      <td>b'1'</td>\n      <td>b'1'</td>\n      <td>b'1'</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"dating.info()","metadata":{"execution":{"iopub.status.busy":"2023-02-27T09:52:14.409320Z","iopub.execute_input":"2023-02-27T09:52:14.410238Z","iopub.status.idle":"2023-02-27T09:52:14.433181Z","shell.execute_reply.started":"2023-02-27T09:52:14.410187Z","shell.execute_reply":"2023-02-27T09:52:14.431114Z"},"trusted":true},"execution_count":188,"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 8378 entries, 0 to 8377\nColumns: 123 entries, has_null to match\ndtypes: float64(59), object(64)\nmemory usage: 7.9+ MB\n","output_type":"stream"}]},{"cell_type":"code","source":"dating.shape","metadata":{"execution":{"iopub.status.busy":"2023-02-27T09:52:14.436054Z","iopub.execute_input":"2023-02-27T09:52:14.436417Z","iopub.status.idle":"2023-02-27T09:52:14.444320Z","shell.execute_reply.started":"2023-02-27T09:52:14.436387Z","shell.execute_reply":"2023-02-27T09:52:14.442945Z"},"trusted":true},"execution_count":189,"outputs":[{"execution_count":189,"output_type":"execute_result","data":{"text/plain":"(8378, 123)"},"metadata":{}}]},{"cell_type":"markdown","source":"<h1 style=\"font-family:monospace\">4. Data preprocessing</h1>\n<h2 style=\"font-family:monospace; margin-left: 25px\">4.1 Checking column data types</h2>","metadata":{}},{"cell_type":"code","source":"dating.dtypes","metadata":{"execution":{"iopub.status.busy":"2023-02-27T09:52:14.445732Z","iopub.execute_input":"2023-02-27T09:52:14.446186Z","iopub.status.idle":"2023-02-27T09:52:14.461649Z","shell.execute_reply.started":"2023-02-27T09:52:14.446149Z","shell.execute_reply":"2023-02-27T09:52:14.460196Z"},"trusted":true},"execution_count":190,"outputs":[{"execution_count":190,"output_type":"execute_result","data":{"text/plain":"has_null                            object\nwave                               float64\ngender                              object\nage                                float64\nage_o                              float64\nd_age                              float64\nd_d_age                             object\nrace                                object\nrace_o                              object\nsamerace                            object\nimportance_same_race               float64\nimportance_same_religion           float64\nd_importance_same_race              object\nd_importance_same_religion          object\nfield                               object\npref_o_attractive                  float64\npref_o_sincere                     float64\npref_o_intelligence                float64\npref_o_funny                       float64\npref_o_ambitious                   float64\npref_o_shared_interests            float64\nd_pref_o_attractive                 object\nd_pref_o_sincere                    object\nd_pref_o_intelligence               object\nd_pref_o_funny                      object\nd_pref_o_ambitious                  object\nd_pref_o_shared_interests           object\nattractive_o                       float64\nsinsere_o                          float64\nintelligence_o                     float64\nfunny_o                            float64\nambitous_o                         float64\nshared_interests_o                 float64\nd_attractive_o                      object\nd_sinsere_o                         object\nd_intelligence_o                    object\nd_funny_o                           object\nd_ambitous_o                        object\nd_shared_interests_o                object\nattractive_important               float64\nsincere_important                  float64\nintellicence_important             float64\nfunny_important                    float64\nambtition_important                float64\nshared_interests_important         float64\nd_attractive_important              object\nd_sincere_important                 object\nd_intellicence_important            object\nd_funny_important                   object\nd_ambtition_important               object\nd_shared_interests_important        object\nattractive                         float64\nsincere                            float64\nintelligence                       float64\nfunny                              float64\nambition                           float64\nd_attractive                        object\nd_sincere                           object\nd_intelligence                      object\nd_funny                             object\nd_ambition                          object\nattractive_partner                 float64\nsincere_partner                    float64\nintelligence_partner               float64\nfunny_partner                      float64\nambition_partner                   float64\nshared_interests_partner           float64\nd_attractive_partner                object\nd_sincere_partner                   object\nd_intelligence_partner              object\nd_funny_partner                     object\nd_ambition_partner                  object\nd_shared_interests_partner          object\nsports                             float64\ntvsports                           float64\nexercise                           float64\ndining                             float64\nmuseums                            float64\nart                                float64\nhiking                             float64\ngaming                             float64\nclubbing                           float64\nreading                            float64\ntv                                 float64\ntheater                            float64\nmovies                             float64\nconcerts                           float64\nmusic                              float64\nshopping                           float64\nyoga                               float64\nd_sports                            object\nd_tvsports                          object\nd_exercise                          object\nd_dining                            object\nd_museums                           object\nd_art                               object\nd_hiking                            object\nd_gaming                            object\nd_clubbing                          object\nd_reading                           object\nd_tv                                object\nd_theater                           object\nd_movies                            object\nd_concerts                          object\nd_music                             object\nd_shopping                          object\nd_yoga                              object\ninterests_correlate                float64\nd_interests_correlate               object\nexpected_happy_with_sd_people      float64\nexpected_num_interested_in_me      float64\nexpected_num_matches               float64\nd_expected_happy_with_sd_people     object\nd_expected_num_interested_in_me     object\nd_expected_num_matches              object\nlike                               float64\nguess_prob_liked                   float64\nd_like                              object\nd_guess_prob_liked                  object\nmet                                float64\ndecision                            object\ndecision_o                          object\nmatch                               object\ndtype: object"},"metadata":{}}]},{"cell_type":"markdown","source":"<h2 style=\"font-family:monospace; margin-left: 25px\">4.2 Removing unwanted characters</h2>\n<p style = \"font-family:georgia, serif; font-size:17px\">\nAll string columns have an unwanted character 'b' and are enclosed by single quotes. We will remove these characters from the columns.</p>","metadata":{}},{"cell_type":"code","source":"dating.head(3)","metadata":{"execution":{"iopub.status.busy":"2023-02-27T09:52:14.463401Z","iopub.execute_input":"2023-02-27T09:52:14.463743Z","iopub.status.idle":"2023-02-27T09:52:14.572770Z","shell.execute_reply.started":"2023-02-27T09:52:14.463714Z","shell.execute_reply":"2023-02-27T09:52:14.571413Z"},"trusted":true},"execution_count":191,"outputs":[{"execution_count":191,"output_type":"execute_result","data":{"text/plain":"  has_null  wave     gender   age  age_o  d_age   d_d_age  \\\n0      b''   1.0  b'female'  21.0   27.0    6.0  b'[4-6]'   \n1      b''   1.0  b'female'  21.0   22.0    1.0  b'[0-1]'   \n2      b''   1.0  b'female'  21.0   22.0    1.0  b'[0-1]'   \n\n                                       race  \\\n0  b'Asian/Pacific Islander/Asian-American'   \n1  b'Asian/Pacific Islander/Asian-American'   \n2  b'Asian/Pacific Islander/Asian-American'   \n\n                                     race_o samerace  importance_same_race  \\\n0            b'European/Caucasian-American'     b'0'                   2.0   \n1            b'European/Caucasian-American'     b'0'                   2.0   \n2  b'Asian/Pacific Islander/Asian-American'     b'1'                   2.0   \n\n   importance_same_religion d_importance_same_race d_importance_same_religion  \\\n0                       4.0               b'[2-5]'                   b'[2-5]'   \n1                       4.0               b'[2-5]'                   b'[2-5]'   \n2                       4.0               b'[2-5]'                   b'[2-5]'   \n\n    field  pref_o_attractive  pref_o_sincere  pref_o_intelligence  \\\n0  b'Law'               35.0            20.0                 20.0   \n1  b'Law'               60.0             0.0                  0.0   \n2  b'Law'               19.0            18.0                 19.0   \n\n   pref_o_funny  pref_o_ambitious  pref_o_shared_interests  \\\n0          20.0               0.0                      5.0   \n1          40.0               0.0                      0.0   \n2          18.0              14.0                     12.0   \n\n  d_pref_o_attractive d_pref_o_sincere d_pref_o_intelligence d_pref_o_funny  \\\n0         b'[21-100]'       b'[16-20]'            b'[16-20]'     b'[16-20]'   \n1         b'[21-100]'        b'[0-15]'             b'[0-15]'    b'[21-100]'   \n2          b'[16-20]'       b'[16-20]'            b'[16-20]'     b'[16-20]'   \n\n  d_pref_o_ambitious d_pref_o_shared_interests  attractive_o  sinsere_o  \\\n0          b'[0-15]'                 b'[0-15]'           6.0        8.0   \n1          b'[0-15]'                 b'[0-15]'           7.0        8.0   \n2          b'[0-15]'                 b'[0-15]'          10.0       10.0   \n\n   intelligence_o  funny_o  ambitous_o  shared_interests_o d_attractive_o  \\\n0             8.0      8.0         8.0                 6.0       b'[6-8]'   \n1            10.0      7.0         7.0                 5.0       b'[6-8]'   \n2            10.0     10.0        10.0                10.0      b'[9-10]'   \n\n  d_sinsere_o d_intelligence_o  d_funny_o d_ambitous_o d_shared_interests_o  \\\n0    b'[6-8]'         b'[6-8]'   b'[6-8]'     b'[6-8]'             b'[6-8]'   \n1    b'[6-8]'        b'[9-10]'   b'[6-8]'     b'[6-8]'             b'[0-5]'   \n2   b'[9-10]'        b'[9-10]'  b'[9-10]'    b'[9-10]'            b'[9-10]'   \n\n   attractive_important  sincere_important  intellicence_important  \\\n0                  15.0               20.0                    20.0   \n1                  15.0               20.0                    20.0   \n2                  15.0               20.0                    20.0   \n\n   funny_important  ambtition_important  shared_interests_important  \\\n0             15.0                 15.0                        15.0   \n1             15.0                 15.0                        15.0   \n2             15.0                 15.0                        15.0   \n\n  d_attractive_important d_sincere_important d_intellicence_important  \\\n0              b'[0-15]'          b'[16-20]'               b'[16-20]'   \n1              b'[0-15]'          b'[16-20]'               b'[16-20]'   \n2              b'[0-15]'          b'[16-20]'               b'[16-20]'   \n\n  d_funny_important d_ambtition_important d_shared_interests_important  \\\n0         b'[0-15]'             b'[0-15]'                    b'[0-15]'   \n1         b'[0-15]'             b'[0-15]'                    b'[0-15]'   \n2         b'[0-15]'             b'[0-15]'                    b'[0-15]'   \n\n   attractive  sincere  intelligence  funny  ambition d_attractive d_sincere  \\\n0         6.0      8.0           8.0    8.0       7.0     b'[6-8]'  b'[6-8]'   \n1         6.0      8.0           8.0    8.0       7.0     b'[6-8]'  b'[6-8]'   \n2         6.0      8.0           8.0    8.0       7.0     b'[6-8]'  b'[6-8]'   \n\n  d_intelligence   d_funny d_ambition  attractive_partner  sincere_partner  \\\n0       b'[6-8]'  b'[6-8]'   b'[6-8]'                 6.0              9.0   \n1       b'[6-8]'  b'[6-8]'   b'[6-8]'                 7.0              8.0   \n2       b'[6-8]'  b'[6-8]'   b'[6-8]'                 5.0              8.0   \n\n   intelligence_partner  funny_partner  ambition_partner  \\\n0                   7.0            7.0               6.0   \n1                   7.0            8.0               5.0   \n2                   9.0            8.0               5.0   \n\n   shared_interests_partner d_attractive_partner d_sincere_partner  \\\n0                       5.0             b'[6-8]'         b'[9-10]'   \n1                       6.0             b'[6-8]'          b'[6-8]'   \n2                       7.0             b'[0-5]'          b'[6-8]'   \n\n  d_intelligence_partner d_funny_partner d_ambition_partner  \\\n0               b'[6-8]'        b'[6-8]'           b'[6-8]'   \n1               b'[6-8]'        b'[6-8]'           b'[0-5]'   \n2              b'[9-10]'        b'[6-8]'           b'[0-5]'   \n\n  d_shared_interests_partner  sports  tvsports  exercise  dining  museums  \\\n0                   b'[0-5]'     9.0       2.0       8.0     9.0      1.0   \n1                   b'[6-8]'     9.0       2.0       8.0     9.0      1.0   \n2                   b'[6-8]'     9.0       2.0       8.0     9.0      1.0   \n\n   art  hiking  gaming  clubbing  reading   tv  theater  movies  concerts  \\\n0  1.0     5.0     1.0       5.0      6.0  9.0      1.0    10.0      10.0   \n1  1.0     5.0     1.0       5.0      6.0  9.0      1.0    10.0      10.0   \n2  1.0     5.0     1.0       5.0      6.0  9.0      1.0    10.0      10.0   \n\n   music  shopping  yoga   d_sports d_tvsports d_exercise   d_dining  \\\n0    9.0       8.0   1.0  b'[9-10]'   b'[0-5]'   b'[6-8]'  b'[9-10]'   \n1    9.0       8.0   1.0  b'[9-10]'   b'[0-5]'   b'[6-8]'  b'[9-10]'   \n2    9.0       8.0   1.0  b'[9-10]'   b'[0-5]'   b'[6-8]'  b'[9-10]'   \n\n  d_museums     d_art  d_hiking  d_gaming d_clubbing d_reading       d_tv  \\\n0  b'[0-5]'  b'[0-5]'  b'[0-5]'  b'[0-5]'   b'[0-5]'  b'[6-8]'  b'[9-10]'   \n1  b'[0-5]'  b'[0-5]'  b'[0-5]'  b'[0-5]'   b'[0-5]'  b'[6-8]'  b'[9-10]'   \n2  b'[0-5]'  b'[0-5]'  b'[0-5]'  b'[0-5]'   b'[0-5]'  b'[6-8]'  b'[9-10]'   \n\n  d_theater   d_movies d_concerts    d_music d_shopping    d_yoga  \\\n0  b'[0-5]'  b'[9-10]'  b'[9-10]'  b'[9-10]'   b'[6-8]'  b'[0-5]'   \n1  b'[0-5]'  b'[9-10]'  b'[9-10]'  b'[9-10]'   b'[6-8]'  b'[0-5]'   \n2  b'[0-5]'  b'[9-10]'  b'[9-10]'  b'[9-10]'   b'[6-8]'  b'[0-5]'   \n\n   interests_correlate d_interests_correlate  expected_happy_with_sd_people  \\\n0                 0.14           b'[0-0.33]'                            3.0   \n1                 0.54           b'[0.33-1]'                            3.0   \n2                 0.16           b'[0-0.33]'                            3.0   \n\n   expected_num_interested_in_me  expected_num_matches  \\\n0                            2.0                   4.0   \n1                            2.0                   4.0   \n2                            2.0                   4.0   \n\n  d_expected_happy_with_sd_people d_expected_num_interested_in_me  \\\n0                        b'[0-4]'                        b'[0-3]'   \n1                        b'[0-4]'                        b'[0-3]'   \n2                        b'[0-4]'                        b'[0-3]'   \n\n  d_expected_num_matches  like  guess_prob_liked    d_like d_guess_prob_liked  \\\n0               b'[3-5]'   7.0               6.0  b'[6-8]'           b'[5-6]'   \n1               b'[3-5]'   7.0               5.0  b'[6-8]'           b'[5-6]'   \n2               b'[3-5]'   7.0               NaN  b'[6-8]'           b'[0-4]'   \n\n   met decision decision_o match  \n0  0.0     b'1'       b'0'  b'0'  \n1  1.0     b'1'       b'0'  b'0'  \n2  1.0     b'1'       b'1'  b'1'  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>has_null</th>\n      <th>wave</th>\n      <th>gender</th>\n      <th>age</th>\n      <th>age_o</th>\n      <th>d_age</th>\n      <th>d_d_age</th>\n      <th>race</th>\n      <th>race_o</th>\n      <th>samerace</th>\n      <th>importance_same_race</th>\n      <th>importance_same_religion</th>\n      <th>d_importance_same_race</th>\n      <th>d_importance_same_religion</th>\n      <th>field</th>\n      <th>pref_o_attractive</th>\n      <th>pref_o_sincere</th>\n      <th>pref_o_intelligence</th>\n      <th>pref_o_funny</th>\n      <th>pref_o_ambitious</th>\n      <th>pref_o_shared_interests</th>\n      <th>d_pref_o_attractive</th>\n      <th>d_pref_o_sincere</th>\n      <th>d_pref_o_intelligence</th>\n      <th>d_pref_o_funny</th>\n      <th>d_pref_o_ambitious</th>\n      <th>d_pref_o_shared_interests</th>\n      <th>attractive_o</th>\n      <th>sinsere_o</th>\n      <th>intelligence_o</th>\n      <th>funny_o</th>\n      <th>ambitous_o</th>\n      <th>shared_interests_o</th>\n      <th>d_attractive_o</th>\n      <th>d_sinsere_o</th>\n      <th>d_intelligence_o</th>\n      <th>d_funny_o</th>\n      <th>d_ambitous_o</th>\n      <th>d_shared_interests_o</th>\n      <th>attractive_important</th>\n      <th>sincere_important</th>\n      <th>intellicence_important</th>\n      <th>funny_important</th>\n      <th>ambtition_important</th>\n      <th>shared_interests_important</th>\n      <th>d_attractive_important</th>\n      <th>d_sincere_important</th>\n      <th>d_intellicence_important</th>\n      <th>d_funny_important</th>\n      <th>d_ambtition_important</th>\n      <th>d_shared_interests_important</th>\n      <th>attractive</th>\n      <th>sincere</th>\n      <th>intelligence</th>\n      <th>funny</th>\n      <th>ambition</th>\n      <th>d_attractive</th>\n      <th>d_sincere</th>\n      <th>d_intelligence</th>\n      <th>d_funny</th>\n      <th>d_ambition</th>\n      <th>attractive_partner</th>\n      <th>sincere_partner</th>\n      <th>intelligence_partner</th>\n      <th>funny_partner</th>\n      <th>ambition_partner</th>\n      <th>shared_interests_partner</th>\n      <th>d_attractive_partner</th>\n      <th>d_sincere_partner</th>\n      <th>d_intelligence_partner</th>\n      <th>d_funny_partner</th>\n      <th>d_ambition_partner</th>\n      <th>d_shared_interests_partner</th>\n      <th>sports</th>\n      <th>tvsports</th>\n      <th>exercise</th>\n      <th>dining</th>\n      <th>museums</th>\n      <th>art</th>\n      <th>hiking</th>\n      <th>gaming</th>\n      <th>clubbing</th>\n      <th>reading</th>\n      <th>tv</th>\n      <th>theater</th>\n      <th>movies</th>\n      <th>concerts</th>\n      <th>music</th>\n      <th>shopping</th>\n      <th>yoga</th>\n      <th>d_sports</th>\n      <th>d_tvsports</th>\n      <th>d_exercise</th>\n      <th>d_dining</th>\n      <th>d_museums</th>\n      <th>d_art</th>\n      <th>d_hiking</th>\n      <th>d_gaming</th>\n      <th>d_clubbing</th>\n      <th>d_reading</th>\n      <th>d_tv</th>\n      <th>d_theater</th>\n      <th>d_movies</th>\n      <th>d_concerts</th>\n      <th>d_music</th>\n      <th>d_shopping</th>\n      <th>d_yoga</th>\n      <th>interests_correlate</th>\n      <th>d_interests_correlate</th>\n      <th>expected_happy_with_sd_people</th>\n      <th>expected_num_interested_in_me</th>\n      <th>expected_num_matches</th>\n      <th>d_expected_happy_with_sd_people</th>\n      <th>d_expected_num_interested_in_me</th>\n      <th>d_expected_num_matches</th>\n      <th>like</th>\n      <th>guess_prob_liked</th>\n      <th>d_like</th>\n      <th>d_guess_prob_liked</th>\n      <th>met</th>\n      <th>decision</th>\n      <th>decision_o</th>\n      <th>match</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>b''</td>\n      <td>1.0</td>\n      <td>b'female'</td>\n      <td>21.0</td>\n      <td>27.0</td>\n      <td>6.0</td>\n      <td>b'[4-6]'</td>\n      <td>b'Asian/Pacific Islander/Asian-American'</td>\n      <td>b'European/Caucasian-American'</td>\n      <td>b'0'</td>\n      <td>2.0</td>\n      <td>4.0</td>\n      <td>b'[2-5]'</td>\n      <td>b'[2-5]'</td>\n      <td>b'Law'</td>\n      <td>35.0</td>\n      <td>20.0</td>\n      <td>20.0</td>\n      <td>20.0</td>\n      <td>0.0</td>\n      <td>5.0</td>\n      <td>b'[21-100]'</td>\n      <td>b'[16-20]'</td>\n      <td>b'[16-20]'</td>\n      <td>b'[16-20]'</td>\n      <td>b'[0-15]'</td>\n      <td>b'[0-15]'</td>\n      <td>6.0</td>\n      <td>8.0</td>\n      <td>8.0</td>\n      <td>8.0</td>\n      <td>8.0</td>\n      <td>6.0</td>\n      <td>b'[6-8]'</td>\n      <td>b'[6-8]'</td>\n      <td>b'[6-8]'</td>\n      <td>b'[6-8]'</td>\n      <td>b'[6-8]'</td>\n      <td>b'[6-8]'</td>\n      <td>15.0</td>\n      <td>20.0</td>\n      <td>20.0</td>\n      <td>15.0</td>\n      <td>15.0</td>\n      <td>15.0</td>\n      <td>b'[0-15]'</td>\n      <td>b'[16-20]'</td>\n      <td>b'[16-20]'</td>\n      <td>b'[0-15]'</td>\n      <td>b'[0-15]'</td>\n      <td>b'[0-15]'</td>\n      <td>6.0</td>\n      <td>8.0</td>\n      <td>8.0</td>\n      <td>8.0</td>\n      <td>7.0</td>\n      <td>b'[6-8]'</td>\n      <td>b'[6-8]'</td>\n      <td>b'[6-8]'</td>\n      <td>b'[6-8]'</td>\n      <td>b'[6-8]'</td>\n      <td>6.0</td>\n      <td>9.0</td>\n      <td>7.0</td>\n      <td>7.0</td>\n      <td>6.0</td>\n      <td>5.0</td>\n      <td>b'[6-8]'</td>\n      <td>b'[9-10]'</td>\n      <td>b'[6-8]'</td>\n      <td>b'[6-8]'</td>\n      <td>b'[6-8]'</td>\n      <td>b'[0-5]'</td>\n      <td>9.0</td>\n      <td>2.0</td>\n      <td>8.0</td>\n      <td>9.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>5.0</td>\n      <td>1.0</td>\n      <td>5.0</td>\n      <td>6.0</td>\n      <td>9.0</td>\n      <td>1.0</td>\n      <td>10.0</td>\n      <td>10.0</td>\n      <td>9.0</td>\n      <td>8.0</td>\n      <td>1.0</td>\n      <td>b'[9-10]'</td>\n      <td>b'[0-5]'</td>\n      <td>b'[6-8]'</td>\n      <td>b'[9-10]'</td>\n      <td>b'[0-5]'</td>\n      <td>b'[0-5]'</td>\n      <td>b'[0-5]'</td>\n      <td>b'[0-5]'</td>\n      <td>b'[0-5]'</td>\n      <td>b'[6-8]'</td>\n      <td>b'[9-10]'</td>\n      <td>b'[0-5]'</td>\n      <td>b'[9-10]'</td>\n      <td>b'[9-10]'</td>\n      <td>b'[9-10]'</td>\n      <td>b'[6-8]'</td>\n      <td>b'[0-5]'</td>\n      <td>0.14</td>\n      <td>b'[0-0.33]'</td>\n      <td>3.0</td>\n      <td>2.0</td>\n      <td>4.0</td>\n      <td>b'[0-4]'</td>\n      <td>b'[0-3]'</td>\n      <td>b'[3-5]'</td>\n      <td>7.0</td>\n      <td>6.0</td>\n      <td>b'[6-8]'</td>\n      <td>b'[5-6]'</td>\n      <td>0.0</td>\n      <td>b'1'</td>\n      <td>b'0'</td>\n      <td>b'0'</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>b''</td>\n      <td>1.0</td>\n      <td>b'female'</td>\n      <td>21.0</td>\n      <td>22.0</td>\n      <td>1.0</td>\n      <td>b'[0-1]'</td>\n      <td>b'Asian/Pacific Islander/Asian-American'</td>\n      <td>b'European/Caucasian-American'</td>\n      <td>b'0'</td>\n      <td>2.0</td>\n      <td>4.0</td>\n      <td>b'[2-5]'</td>\n      <td>b'[2-5]'</td>\n      <td>b'Law'</td>\n      <td>60.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>40.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>b'[21-100]'</td>\n      <td>b'[0-15]'</td>\n      <td>b'[0-15]'</td>\n      <td>b'[21-100]'</td>\n      <td>b'[0-15]'</td>\n      <td>b'[0-15]'</td>\n      <td>7.0</td>\n      <td>8.0</td>\n      <td>10.0</td>\n      <td>7.0</td>\n      <td>7.0</td>\n      <td>5.0</td>\n      <td>b'[6-8]'</td>\n      <td>b'[6-8]'</td>\n      <td>b'[9-10]'</td>\n      <td>b'[6-8]'</td>\n      <td>b'[6-8]'</td>\n      <td>b'[0-5]'</td>\n      <td>15.0</td>\n      <td>20.0</td>\n      <td>20.0</td>\n      <td>15.0</td>\n      <td>15.0</td>\n      <td>15.0</td>\n      <td>b'[0-15]'</td>\n      <td>b'[16-20]'</td>\n      <td>b'[16-20]'</td>\n      <td>b'[0-15]'</td>\n      <td>b'[0-15]'</td>\n      <td>b'[0-15]'</td>\n      <td>6.0</td>\n      <td>8.0</td>\n      <td>8.0</td>\n      <td>8.0</td>\n      <td>7.0</td>\n      <td>b'[6-8]'</td>\n      <td>b'[6-8]'</td>\n      <td>b'[6-8]'</td>\n      <td>b'[6-8]'</td>\n      <td>b'[6-8]'</td>\n      <td>7.0</td>\n      <td>8.0</td>\n      <td>7.0</td>\n      <td>8.0</td>\n      <td>5.0</td>\n      <td>6.0</td>\n      <td>b'[6-8]'</td>\n      <td>b'[6-8]'</td>\n      <td>b'[6-8]'</td>\n      <td>b'[6-8]'</td>\n      <td>b'[0-5]'</td>\n      <td>b'[6-8]'</td>\n      <td>9.0</td>\n      <td>2.0</td>\n      <td>8.0</td>\n      <td>9.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>5.0</td>\n      <td>1.0</td>\n      <td>5.0</td>\n      <td>6.0</td>\n      <td>9.0</td>\n      <td>1.0</td>\n      <td>10.0</td>\n      <td>10.0</td>\n      <td>9.0</td>\n      <td>8.0</td>\n      <td>1.0</td>\n      <td>b'[9-10]'</td>\n      <td>b'[0-5]'</td>\n      <td>b'[6-8]'</td>\n      <td>b'[9-10]'</td>\n      <td>b'[0-5]'</td>\n      <td>b'[0-5]'</td>\n      <td>b'[0-5]'</td>\n      <td>b'[0-5]'</td>\n      <td>b'[0-5]'</td>\n      <td>b'[6-8]'</td>\n      <td>b'[9-10]'</td>\n      <td>b'[0-5]'</td>\n      <td>b'[9-10]'</td>\n      <td>b'[9-10]'</td>\n      <td>b'[9-10]'</td>\n      <td>b'[6-8]'</td>\n      <td>b'[0-5]'</td>\n      <td>0.54</td>\n      <td>b'[0.33-1]'</td>\n      <td>3.0</td>\n      <td>2.0</td>\n      <td>4.0</td>\n      <td>b'[0-4]'</td>\n      <td>b'[0-3]'</td>\n      <td>b'[3-5]'</td>\n      <td>7.0</td>\n      <td>5.0</td>\n      <td>b'[6-8]'</td>\n      <td>b'[5-6]'</td>\n      <td>1.0</td>\n      <td>b'1'</td>\n      <td>b'0'</td>\n      <td>b'0'</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>b''</td>\n      <td>1.0</td>\n      <td>b'female'</td>\n      <td>21.0</td>\n      <td>22.0</td>\n      <td>1.0</td>\n      <td>b'[0-1]'</td>\n      <td>b'Asian/Pacific Islander/Asian-American'</td>\n      <td>b'Asian/Pacific Islander/Asian-American'</td>\n      <td>b'1'</td>\n      <td>2.0</td>\n      <td>4.0</td>\n      <td>b'[2-5]'</td>\n      <td>b'[2-5]'</td>\n      <td>b'Law'</td>\n      <td>19.0</td>\n      <td>18.0</td>\n      <td>19.0</td>\n      <td>18.0</td>\n      <td>14.0</td>\n      <td>12.0</td>\n      <td>b'[16-20]'</td>\n      <td>b'[16-20]'</td>\n      <td>b'[16-20]'</td>\n      <td>b'[16-20]'</td>\n      <td>b'[0-15]'</td>\n      <td>b'[0-15]'</td>\n      <td>10.0</td>\n      <td>10.0</td>\n      <td>10.0</td>\n      <td>10.0</td>\n      <td>10.0</td>\n      <td>10.0</td>\n      <td>b'[9-10]'</td>\n      <td>b'[9-10]'</td>\n      <td>b'[9-10]'</td>\n      <td>b'[9-10]'</td>\n      <td>b'[9-10]'</td>\n      <td>b'[9-10]'</td>\n      <td>15.0</td>\n      <td>20.0</td>\n      <td>20.0</td>\n      <td>15.0</td>\n      <td>15.0</td>\n      <td>15.0</td>\n      <td>b'[0-15]'</td>\n      <td>b'[16-20]'</td>\n      <td>b'[16-20]'</td>\n      <td>b'[0-15]'</td>\n      <td>b'[0-15]'</td>\n      <td>b'[0-15]'</td>\n      <td>6.0</td>\n      <td>8.0</td>\n      <td>8.0</td>\n      <td>8.0</td>\n      <td>7.0</td>\n      <td>b'[6-8]'</td>\n      <td>b'[6-8]'</td>\n      <td>b'[6-8]'</td>\n      <td>b'[6-8]'</td>\n      <td>b'[6-8]'</td>\n      <td>5.0</td>\n      <td>8.0</td>\n      <td>9.0</td>\n      <td>8.0</td>\n      <td>5.0</td>\n      <td>7.0</td>\n      <td>b'[0-5]'</td>\n      <td>b'[6-8]'</td>\n      <td>b'[9-10]'</td>\n      <td>b'[6-8]'</td>\n      <td>b'[0-5]'</td>\n      <td>b'[6-8]'</td>\n      <td>9.0</td>\n      <td>2.0</td>\n      <td>8.0</td>\n      <td>9.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>5.0</td>\n      <td>1.0</td>\n      <td>5.0</td>\n      <td>6.0</td>\n      <td>9.0</td>\n      <td>1.0</td>\n      <td>10.0</td>\n      <td>10.0</td>\n      <td>9.0</td>\n      <td>8.0</td>\n      <td>1.0</td>\n      <td>b'[9-10]'</td>\n      <td>b'[0-5]'</td>\n      <td>b'[6-8]'</td>\n      <td>b'[9-10]'</td>\n      <td>b'[0-5]'</td>\n      <td>b'[0-5]'</td>\n      <td>b'[0-5]'</td>\n      <td>b'[0-5]'</td>\n      <td>b'[0-5]'</td>\n      <td>b'[6-8]'</td>\n      <td>b'[9-10]'</td>\n      <td>b'[0-5]'</td>\n      <td>b'[9-10]'</td>\n      <td>b'[9-10]'</td>\n      <td>b'[9-10]'</td>\n      <td>b'[6-8]'</td>\n      <td>b'[0-5]'</td>\n      <td>0.16</td>\n      <td>b'[0-0.33]'</td>\n      <td>3.0</td>\n      <td>2.0</td>\n      <td>4.0</td>\n      <td>b'[0-4]'</td>\n      <td>b'[0-3]'</td>\n      <td>b'[3-5]'</td>\n      <td>7.0</td>\n      <td>NaN</td>\n      <td>b'[6-8]'</td>\n      <td>b'[0-4]'</td>\n      <td>1.0</td>\n      <td>b'1'</td>\n      <td>b'1'</td>\n      <td>b'1'</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# We create a function that removes all the unwanted characters\ndef remove_xters(feature):\n    return feature.replace(\"b'\",'').replace(\"'\",\"\")\n\n# We select string columns and apply the transformation\nstring_dataset = dating.select_dtypes(include = ['object'])\n\nfor feature in string_dataset.columns:\n    dating[feature] = dating[feature].apply(lambda x: remove_xters(x))\n    \ndating[string_dataset.columns].head(3)","metadata":{"execution":{"iopub.status.busy":"2023-02-27T09:52:14.574273Z","iopub.execute_input":"2023-02-27T09:52:14.574626Z","iopub.status.idle":"2023-02-27T09:52:15.030843Z","shell.execute_reply.started":"2023-02-27T09:52:14.574595Z","shell.execute_reply":"2023-02-27T09:52:15.029650Z"},"trusted":true},"execution_count":192,"outputs":[{"execution_count":192,"output_type":"execute_result","data":{"text/plain":"  has_null  gender d_d_age                                   race  \\\n0           female   [4-6]  Asian/Pacific Islander/Asian-American   \n1           female   [0-1]  Asian/Pacific Islander/Asian-American   \n2           female   [0-1]  Asian/Pacific Islander/Asian-American   \n\n                                  race_o samerace d_importance_same_race  \\\n0            European/Caucasian-American        0                  [2-5]   \n1            European/Caucasian-American        0                  [2-5]   \n2  Asian/Pacific Islander/Asian-American        1                  [2-5]   \n\n  d_importance_same_religion field d_pref_o_attractive d_pref_o_sincere  \\\n0                      [2-5]   Law            [21-100]          [16-20]   \n1                      [2-5]   Law            [21-100]           [0-15]   \n2                      [2-5]   Law             [16-20]          [16-20]   \n\n  d_pref_o_intelligence d_pref_o_funny d_pref_o_ambitious  \\\n0               [16-20]        [16-20]             [0-15]   \n1                [0-15]       [21-100]             [0-15]   \n2               [16-20]        [16-20]             [0-15]   \n\n  d_pref_o_shared_interests d_attractive_o d_sinsere_o d_intelligence_o  \\\n0                    [0-15]          [6-8]       [6-8]            [6-8]   \n1                    [0-15]          [6-8]       [6-8]           [9-10]   \n2                    [0-15]         [9-10]      [9-10]           [9-10]   \n\n  d_funny_o d_ambitous_o d_shared_interests_o d_attractive_important  \\\n0     [6-8]        [6-8]                [6-8]                 [0-15]   \n1     [6-8]        [6-8]                [0-5]                 [0-15]   \n2    [9-10]       [9-10]               [9-10]                 [0-15]   \n\n  d_sincere_important d_intellicence_important d_funny_important  \\\n0             [16-20]                  [16-20]            [0-15]   \n1             [16-20]                  [16-20]            [0-15]   \n2             [16-20]                  [16-20]            [0-15]   \n\n  d_ambtition_important d_shared_interests_important d_attractive d_sincere  \\\n0                [0-15]                       [0-15]        [6-8]     [6-8]   \n1                [0-15]                       [0-15]        [6-8]     [6-8]   \n2                [0-15]                       [0-15]        [6-8]     [6-8]   \n\n  d_intelligence d_funny d_ambition d_attractive_partner d_sincere_partner  \\\n0          [6-8]   [6-8]      [6-8]                [6-8]            [9-10]   \n1          [6-8]   [6-8]      [6-8]                [6-8]             [6-8]   \n2          [6-8]   [6-8]      [6-8]                [0-5]             [6-8]   \n\n  d_intelligence_partner d_funny_partner d_ambition_partner  \\\n0                  [6-8]           [6-8]              [6-8]   \n1                  [6-8]           [6-8]              [0-5]   \n2                 [9-10]           [6-8]              [0-5]   \n\n  d_shared_interests_partner d_sports d_tvsports d_exercise d_dining  \\\n0                      [0-5]   [9-10]      [0-5]      [6-8]   [9-10]   \n1                      [6-8]   [9-10]      [0-5]      [6-8]   [9-10]   \n2                      [6-8]   [9-10]      [0-5]      [6-8]   [9-10]   \n\n  d_museums  d_art d_hiking d_gaming d_clubbing d_reading    d_tv d_theater  \\\n0     [0-5]  [0-5]    [0-5]    [0-5]      [0-5]     [6-8]  [9-10]     [0-5]   \n1     [0-5]  [0-5]    [0-5]    [0-5]      [0-5]     [6-8]  [9-10]     [0-5]   \n2     [0-5]  [0-5]    [0-5]    [0-5]      [0-5]     [6-8]  [9-10]     [0-5]   \n\n  d_movies d_concerts d_music d_shopping d_yoga d_interests_correlate  \\\n0   [9-10]     [9-10]  [9-10]      [6-8]  [0-5]              [0-0.33]   \n1   [9-10]     [9-10]  [9-10]      [6-8]  [0-5]              [0.33-1]   \n2   [9-10]     [9-10]  [9-10]      [6-8]  [0-5]              [0-0.33]   \n\n  d_expected_happy_with_sd_people d_expected_num_interested_in_me  \\\n0                           [0-4]                           [0-3]   \n1                           [0-4]                           [0-3]   \n2                           [0-4]                           [0-3]   \n\n  d_expected_num_matches d_like d_guess_prob_liked decision decision_o match  \n0                  [3-5]  [6-8]              [5-6]        1          0     0  \n1                  [3-5]  [6-8]              [5-6]        1          0     0  \n2                  [3-5]  [6-8]              [0-4]        1          1     1  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>has_null</th>\n      <th>gender</th>\n      <th>d_d_age</th>\n      <th>race</th>\n      <th>race_o</th>\n      <th>samerace</th>\n      <th>d_importance_same_race</th>\n      <th>d_importance_same_religion</th>\n      <th>field</th>\n      <th>d_pref_o_attractive</th>\n      <th>d_pref_o_sincere</th>\n      <th>d_pref_o_intelligence</th>\n      <th>d_pref_o_funny</th>\n      <th>d_pref_o_ambitious</th>\n      <th>d_pref_o_shared_interests</th>\n      <th>d_attractive_o</th>\n      <th>d_sinsere_o</th>\n      <th>d_intelligence_o</th>\n      <th>d_funny_o</th>\n      <th>d_ambitous_o</th>\n      <th>d_shared_interests_o</th>\n      <th>d_attractive_important</th>\n      <th>d_sincere_important</th>\n      <th>d_intellicence_important</th>\n      <th>d_funny_important</th>\n      <th>d_ambtition_important</th>\n      <th>d_shared_interests_important</th>\n      <th>d_attractive</th>\n      <th>d_sincere</th>\n      <th>d_intelligence</th>\n      <th>d_funny</th>\n      <th>d_ambition</th>\n      <th>d_attractive_partner</th>\n      <th>d_sincere_partner</th>\n      <th>d_intelligence_partner</th>\n      <th>d_funny_partner</th>\n      <th>d_ambition_partner</th>\n      <th>d_shared_interests_partner</th>\n      <th>d_sports</th>\n      <th>d_tvsports</th>\n      <th>d_exercise</th>\n      <th>d_dining</th>\n      <th>d_museums</th>\n      <th>d_art</th>\n      <th>d_hiking</th>\n      <th>d_gaming</th>\n      <th>d_clubbing</th>\n      <th>d_reading</th>\n      <th>d_tv</th>\n      <th>d_theater</th>\n      <th>d_movies</th>\n      <th>d_concerts</th>\n      <th>d_music</th>\n      <th>d_shopping</th>\n      <th>d_yoga</th>\n      <th>d_interests_correlate</th>\n      <th>d_expected_happy_with_sd_people</th>\n      <th>d_expected_num_interested_in_me</th>\n      <th>d_expected_num_matches</th>\n      <th>d_like</th>\n      <th>d_guess_prob_liked</th>\n      <th>decision</th>\n      <th>decision_o</th>\n      <th>match</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td></td>\n      <td>female</td>\n      <td>[4-6]</td>\n      <td>Asian/Pacific Islander/Asian-American</td>\n      <td>European/Caucasian-American</td>\n      <td>0</td>\n      <td>[2-5]</td>\n      <td>[2-5]</td>\n      <td>Law</td>\n      <td>[21-100]</td>\n      <td>[16-20]</td>\n      <td>[16-20]</td>\n      <td>[16-20]</td>\n      <td>[0-15]</td>\n      <td>[0-15]</td>\n      <td>[6-8]</td>\n      <td>[6-8]</td>\n      <td>[6-8]</td>\n      <td>[6-8]</td>\n      <td>[6-8]</td>\n      <td>[6-8]</td>\n      <td>[0-15]</td>\n      <td>[16-20]</td>\n      <td>[16-20]</td>\n      <td>[0-15]</td>\n      <td>[0-15]</td>\n      <td>[0-15]</td>\n      <td>[6-8]</td>\n      <td>[6-8]</td>\n      <td>[6-8]</td>\n      <td>[6-8]</td>\n      <td>[6-8]</td>\n      <td>[6-8]</td>\n      <td>[9-10]</td>\n      <td>[6-8]</td>\n      <td>[6-8]</td>\n      <td>[6-8]</td>\n      <td>[0-5]</td>\n      <td>[9-10]</td>\n      <td>[0-5]</td>\n      <td>[6-8]</td>\n      <td>[9-10]</td>\n      <td>[0-5]</td>\n      <td>[0-5]</td>\n      <td>[0-5]</td>\n      <td>[0-5]</td>\n      <td>[0-5]</td>\n      <td>[6-8]</td>\n      <td>[9-10]</td>\n      <td>[0-5]</td>\n      <td>[9-10]</td>\n      <td>[9-10]</td>\n      <td>[9-10]</td>\n      <td>[6-8]</td>\n      <td>[0-5]</td>\n      <td>[0-0.33]</td>\n      <td>[0-4]</td>\n      <td>[0-3]</td>\n      <td>[3-5]</td>\n      <td>[6-8]</td>\n      <td>[5-6]</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td></td>\n      <td>female</td>\n      <td>[0-1]</td>\n      <td>Asian/Pacific Islander/Asian-American</td>\n      <td>European/Caucasian-American</td>\n      <td>0</td>\n      <td>[2-5]</td>\n      <td>[2-5]</td>\n      <td>Law</td>\n      <td>[21-100]</td>\n      <td>[0-15]</td>\n      <td>[0-15]</td>\n      <td>[21-100]</td>\n      <td>[0-15]</td>\n      <td>[0-15]</td>\n      <td>[6-8]</td>\n      <td>[6-8]</td>\n      <td>[9-10]</td>\n      <td>[6-8]</td>\n      <td>[6-8]</td>\n      <td>[0-5]</td>\n      <td>[0-15]</td>\n      <td>[16-20]</td>\n      <td>[16-20]</td>\n      <td>[0-15]</td>\n      <td>[0-15]</td>\n      <td>[0-15]</td>\n      <td>[6-8]</td>\n      <td>[6-8]</td>\n      <td>[6-8]</td>\n      <td>[6-8]</td>\n      <td>[6-8]</td>\n      <td>[6-8]</td>\n      <td>[6-8]</td>\n      <td>[6-8]</td>\n      <td>[6-8]</td>\n      <td>[0-5]</td>\n      <td>[6-8]</td>\n      <td>[9-10]</td>\n      <td>[0-5]</td>\n      <td>[6-8]</td>\n      <td>[9-10]</td>\n      <td>[0-5]</td>\n      <td>[0-5]</td>\n      <td>[0-5]</td>\n      <td>[0-5]</td>\n      <td>[0-5]</td>\n      <td>[6-8]</td>\n      <td>[9-10]</td>\n      <td>[0-5]</td>\n      <td>[9-10]</td>\n      <td>[9-10]</td>\n      <td>[9-10]</td>\n      <td>[6-8]</td>\n      <td>[0-5]</td>\n      <td>[0.33-1]</td>\n      <td>[0-4]</td>\n      <td>[0-3]</td>\n      <td>[3-5]</td>\n      <td>[6-8]</td>\n      <td>[5-6]</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td></td>\n      <td>female</td>\n      <td>[0-1]</td>\n      <td>Asian/Pacific Islander/Asian-American</td>\n      <td>Asian/Pacific Islander/Asian-American</td>\n      <td>1</td>\n      <td>[2-5]</td>\n      <td>[2-5]</td>\n      <td>Law</td>\n      <td>[16-20]</td>\n      <td>[16-20]</td>\n      <td>[16-20]</td>\n      <td>[16-20]</td>\n      <td>[0-15]</td>\n      <td>[0-15]</td>\n      <td>[9-10]</td>\n      <td>[9-10]</td>\n      <td>[9-10]</td>\n      <td>[9-10]</td>\n      <td>[9-10]</td>\n      <td>[9-10]</td>\n      <td>[0-15]</td>\n      <td>[16-20]</td>\n      <td>[16-20]</td>\n      <td>[0-15]</td>\n      <td>[0-15]</td>\n      <td>[0-15]</td>\n      <td>[6-8]</td>\n      <td>[6-8]</td>\n      <td>[6-8]</td>\n      <td>[6-8]</td>\n      <td>[6-8]</td>\n      <td>[0-5]</td>\n      <td>[6-8]</td>\n      <td>[9-10]</td>\n      <td>[6-8]</td>\n      <td>[0-5]</td>\n      <td>[6-8]</td>\n      <td>[9-10]</td>\n      <td>[0-5]</td>\n      <td>[6-8]</td>\n      <td>[9-10]</td>\n      <td>[0-5]</td>\n      <td>[0-5]</td>\n      <td>[0-5]</td>\n      <td>[0-5]</td>\n      <td>[0-5]</td>\n      <td>[6-8]</td>\n      <td>[9-10]</td>\n      <td>[0-5]</td>\n      <td>[9-10]</td>\n      <td>[9-10]</td>\n      <td>[9-10]</td>\n      <td>[6-8]</td>\n      <td>[0-5]</td>\n      <td>[0-0.33]</td>\n      <td>[0-4]</td>\n      <td>[0-3]</td>\n      <td>[3-5]</td>\n      <td>[6-8]</td>\n      <td>[0-4]</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# Drop the has_null and wave columns\ndating.drop(['has_null','wave'], axis = 1, inplace= True)","metadata":{"execution":{"iopub.status.busy":"2023-02-27T09:52:15.032499Z","iopub.execute_input":"2023-02-27T09:52:15.033166Z","iopub.status.idle":"2023-02-27T09:52:15.048019Z","shell.execute_reply.started":"2023-02-27T09:52:15.033126Z","shell.execute_reply":"2023-02-27T09:52:15.046613Z"},"trusted":true},"execution_count":193,"outputs":[]},{"cell_type":"markdown","source":"<p style = \"font-family:georgia, serif; font-size:17px\">The same race variable is a string data type. We convert it to numeric</p>","metadata":{}},{"cell_type":"code","source":"dating['samerace'] = dating['samerace'].astype('int')","metadata":{"execution":{"iopub.status.busy":"2023-02-27T09:52:15.052482Z","iopub.execute_input":"2023-02-27T09:52:15.052897Z","iopub.status.idle":"2023-02-27T09:52:15.082212Z","shell.execute_reply.started":"2023-02-27T09:52:15.052861Z","shell.execute_reply":"2023-02-27T09:52:15.080391Z"},"trusted":true},"execution_count":194,"outputs":[]},{"cell_type":"markdown","source":"<h2 style=\"font-family:monospace; margin-left: 25px\">4.3 Dropping columns</h2>\n<h3 style=\"font-family:monospace; margin-left: 25px\"> 4.3.1 Age</h3>\n\n\n<p style = \"font-family:georgia, serif; font-size:17px\">\nThere are four different columns for age and these are: age of individual, age of partner, age difference, and age group (where ages have been binned into categories). However the age difference column is not standardized since the difference is between the higher age and the lower age. We will standardize the difference by subtracting age between each individual and their partner. Since the direction of the difference matters, the column will have both positive and negative values. We will then drop the other age columns</p>","metadata":{}},{"cell_type":"code","source":"# Create age difference column\ndating['age_diff'] = dating['age'] - dating['age_o']\n\n# Drop other age columns\ndating.drop(['age','age_o', 'd_age', 'd_d_age'], axis = 1, inplace = True)","metadata":{"execution":{"iopub.status.busy":"2023-02-27T09:52:15.084219Z","iopub.execute_input":"2023-02-27T09:52:15.084726Z","iopub.status.idle":"2023-02-27T09:52:15.107336Z","shell.execute_reply.started":"2023-02-27T09:52:15.084693Z","shell.execute_reply":"2023-02-27T09:52:15.106187Z"},"trusted":true},"execution_count":195,"outputs":[]},{"cell_type":"markdown","source":"<h3 style=\"font-family:monospace; margin-left: 25px\">4.3.2 Binned variables</h3>\n<p style = \"font-family:georgia, serif; font-size:17px\">\nThe speed dating dataset has some of the numeric features binned into categories. This is a duplication of information which increases the dimensionality of the dataset without adding any significant value. We will remove all the duplicated features. Conveniently, the names of these binned features have the prefix \"d_\". We will use this to subset and remove these features. Before the selection, the dataset has 118 features, and after the selection, we remain with 64 features.</p>","metadata":{}},{"cell_type":"code","source":"dating.shape","metadata":{"execution":{"iopub.status.busy":"2023-02-27T09:52:15.108887Z","iopub.execute_input":"2023-02-27T09:52:15.109316Z","iopub.status.idle":"2023-02-27T09:52:15.118188Z","shell.execute_reply.started":"2023-02-27T09:52:15.109283Z","shell.execute_reply":"2023-02-27T09:52:15.116573Z"},"trusted":true},"execution_count":196,"outputs":[{"execution_count":196,"output_type":"execute_result","data":{"text/plain":"(8378, 118)"},"metadata":{}}]},{"cell_type":"code","source":"to_drop = [column_name for column_name in dating.columns if column_name.startswith('d_')]\ndating.drop(to_drop, axis = 1, inplace = True)\ndating.shape","metadata":{"execution":{"iopub.status.busy":"2023-02-27T09:52:15.120073Z","iopub.execute_input":"2023-02-27T09:52:15.120522Z","iopub.status.idle":"2023-02-27T09:52:15.138078Z","shell.execute_reply.started":"2023-02-27T09:52:15.120485Z","shell.execute_reply":"2023-02-27T09:52:15.136207Z"},"trusted":true},"execution_count":197,"outputs":[{"execution_count":197,"output_type":"execute_result","data":{"text/plain":"(8378, 64)"},"metadata":{}}]},{"cell_type":"markdown","source":"### <h3 style=\"font-family:monospace; margin-left: 25px\">4.3.3 Field</h3>\n<p style = \"font-family:georgia, serif; font-size:17px\">\nIn the individual field indicating their careers, there's an overlapping of values. For instance, Business, which is the most popular field still comprises of MBA (2nd most popular), Finance, business [MBA] etc. Physics, Chemistry, Biology all fall under science. Due to this variation and overlapping, we will drop the column</p>","metadata":{"execution":{"iopub.status.busy":"2023-02-22T10:31:41.782896Z","iopub.execute_input":"2023-02-22T10:31:41.783299Z","iopub.status.idle":"2023-02-22T10:31:41.790498Z","shell.execute_reply.started":"2023-02-22T10:31:41.783268Z","shell.execute_reply":"2023-02-22T10:31:41.789438Z"}}},{"cell_type":"code","source":"display(dating.field.value_counts().head(30))\ndating.drop('field',axis = 1, inplace = True)","metadata":{"execution":{"iopub.status.busy":"2023-02-27T09:52:15.141049Z","iopub.execute_input":"2023-02-27T09:52:15.142698Z","iopub.status.idle":"2023-02-27T09:52:15.164402Z","shell.execute_reply.started":"2023-02-27T09:52:15.142609Z","shell.execute_reply":"2023-02-27T09:52:15.162805Z"},"trusted":true},"execution_count":198,"outputs":[{"output_type":"display_data","data":{"text/plain":"Business                  521\nMBA                       468\nLaw                       462\nSocial Work               378\nInternational Affairs     252\nElectrical Engineering    164\nPsychology                139\nlaw                       123\nFinance                   113\nbusiness                  110\nMathematics                95\nFilm                       92\nSociology                  88\nBiology                    85\nEngineering                81\nBusiness [MBA]             77\nClinical Psychology        76\nBiochemistry               70\nPolitical Science          69\nEconomics                  67\n?                          63\nchemistry                  57\nPhysics                    56\nOperations Research        56\nSchool Psychology          56\nEducation                  55\nmedicine                   52\nsociology                  52\nMechanical Engineering     51\nUrban Planning             50\nName: field, dtype: int64"},"metadata":{}}]},{"cell_type":"markdown","source":"<h3 style=\"font-family:monospace; margin-left: 25px\">4.3.4 Met</h3>\n<p style = \"font-family:georgia, serif; font-size:17px\">\nThe variable met answers the question as to whether the person has previously met the partner. Since the responses are either yes(1) or no (0), we will clean the column and change responses with neither values, and replace them with the most frequent value. Since they are only a few values, they will not skew our data.</p>","metadata":{}},{"cell_type":"code","source":"print(f'Before \\n{dating.met.value_counts()}')\n\nfor number in [3.0, 5.0, 6.0, 7.0, 8.0]:\n    dating['met'].replace(number,0, inplace =True)\n    \nprint(f'\\nAfter \\n{dating.met.value_counts()}')","metadata":{"execution":{"iopub.status.busy":"2023-02-27T09:52:15.166825Z","iopub.execute_input":"2023-02-27T09:52:15.167273Z","iopub.status.idle":"2023-02-27T09:52:15.181972Z","shell.execute_reply.started":"2023-02-27T09:52:15.167238Z","shell.execute_reply":"2023-02-27T09:52:15.180345Z"},"trusted":true},"execution_count":199,"outputs":[{"name":"stdout","text":"Before \n0.0    7644\n1.0     351\n7.0       3\n5.0       2\n3.0       1\n8.0       1\n6.0       1\nName: met, dtype: int64\n\nAfter \n0.0    7652\n1.0     351\nName: met, dtype: int64\n","output_type":"stream"}]},{"cell_type":"markdown","source":"<h3 style=\"font-family:monospace; margin-left: 25px\">4.3.5 Variables similar to the y variable</h3>\n<p style = \"font-family:georgia, serif; font-size:17px\">The two variables 'decision' and 'decision_o' have similar responses almost similar to the variable being predicted. We will therefore remove these two features.</p>","metadata":{}},{"cell_type":"code","source":"display(dating.groupby('decision')['match'].value_counts())\nprint()\ndisplay(dating.groupby('decision_o')['match'].value_counts())\n\ndating.drop(['decision_o','decision'], axis = 1, inplace = True)","metadata":{"execution":{"iopub.status.busy":"2023-02-27T09:52:15.184157Z","iopub.execute_input":"2023-02-27T09:52:15.185461Z","iopub.status.idle":"2023-02-27T09:52:15.211892Z","shell.execute_reply.started":"2023-02-27T09:52:15.185409Z","shell.execute_reply":"2023-02-27T09:52:15.211026Z"},"trusted":true},"execution_count":200,"outputs":[{"output_type":"display_data","data":{"text/plain":"decision  match\n0         0        4860\n1         0        2138\n          1        1380\nName: match, dtype: int64"},"metadata":{}},{"name":"stdout","text":"\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"decision_o  match\n0           0        4863\n1           0        2135\n            1        1380\nName: match, dtype: int64"},"metadata":{}}]},{"cell_type":"markdown","source":"<h2 style=\"font-family:monospace; margin-left: 25px\">4.4 Numeric and categorical columns</h2>\n","metadata":{"execution":{"iopub.status.busy":"2023-02-27T05:39:01.585535Z","iopub.execute_input":"2023-02-27T05:39:01.586028Z","iopub.status.idle":"2023-02-27T05:39:01.593068Z","shell.execute_reply.started":"2023-02-27T05:39:01.585990Z","shell.execute_reply":"2023-02-27T05:39:01.591328Z"}}},{"cell_type":"code","source":"# Selecting numeric columns\ncolumns_numeric = dating.select_dtypes(include = ['int','float']).columns.tolist()\n\n# Selecting categorical columns\ncolumns_category = dating.select_dtypes(include = ['object']).drop('match', axis=1).columns","metadata":{"execution":{"iopub.status.busy":"2023-02-27T09:52:15.213278Z","iopub.execute_input":"2023-02-27T09:52:15.214445Z","iopub.status.idle":"2023-02-27T09:52:15.228300Z","shell.execute_reply.started":"2023-02-27T09:52:15.214391Z","shell.execute_reply":"2023-02-27T09:52:15.226925Z"},"trusted":true},"execution_count":201,"outputs":[]},{"cell_type":"markdown","source":"<h2 style=\"font-family:monospace; margin-left: 25px\">4.5. Missing values</h2>\n<p style = \"font-family:georgia, serif; font-size:17px\">More than 78% of values in the variable \"expected_num_interested_in_me\" are missing. This variable will therefore be dropped. The rest of the features will be imputed with the median value of each feature.</p>","metadata":{}},{"cell_type":"code","source":"# Show the missing values\ndisplay(dating[columns_numeric].isna().sum()/len(dating)*100)\n\n# Drop the variable with lots of missing values from the dataset\ndating.drop('expected_num_interested_in_me', axis = 1, inplace = True)\n\n# Delete it from the numeric column list\n\ncolumns_numeric.remove('expected_num_interested_in_me')","metadata":{"execution":{"iopub.status.busy":"2023-02-27T09:52:15.230212Z","iopub.execute_input":"2023-02-27T09:52:15.230724Z","iopub.status.idle":"2023-02-27T09:52:15.256282Z","shell.execute_reply.started":"2023-02-27T09:52:15.230678Z","shell.execute_reply":"2023-02-27T09:52:15.254742Z"},"trusted":true},"execution_count":202,"outputs":[{"output_type":"display_data","data":{"text/plain":"samerace                          0.000000\nimportance_same_race              0.942946\nimportance_same_religion          0.942946\npref_o_attractive                 1.062306\npref_o_sincere                    1.062306\npref_o_intelligence               1.062306\npref_o_funny                      1.169730\npref_o_ambitious                  1.277154\npref_o_shared_interests           1.539747\nattractive_o                      2.530437\nsinsere_o                         3.425639\nintelligence_o                    3.652423\nfunny_o                           4.296968\nambitous_o                        8.617809\nshared_interests_o               12.843161\nattractive_important              0.942946\nsincere_important                 0.942946\nintellicence_important            0.942946\nfunny_important                   1.062306\nambtition_important               1.181666\nshared_interests_important        1.444259\nattractive                        1.253282\nsincere                           1.253282\nintelligence                      1.253282\nfunny                             1.253282\nambition                          1.253282\nattractive_partner                2.411077\nsincere_partner                   3.306278\nintelligence_partner              3.533063\nfunny_partner                     4.177608\nambition_partner                  8.498448\nshared_interests_partner         12.735736\nsports                            0.942946\ntvsports                          0.942946\nexercise                          0.942946\ndining                            0.942946\nmuseums                           0.942946\nart                               0.942946\nhiking                            0.942946\ngaming                            0.942946\nclubbing                          0.942946\nreading                           0.942946\ntv                                0.942946\ntheater                           0.942946\nmovies                            0.942946\nconcerts                          0.942946\nmusic                             0.942946\nshopping                          0.942946\nyoga                              0.942946\ninterests_correlate               1.885892\nexpected_happy_with_sd_people     1.205538\nexpected_num_interested_in_me    78.515159\nexpected_num_matches             14.000955\nlike                              2.864646\nguess_prob_liked                  3.688231\nmet                               4.476009\nage_diff                          2.363333\ndtype: float64"},"metadata":{}}]},{"cell_type":"code","source":"# Save the clean dataset for future analysis\ndating.to_csv('/kaggle/working/speed_dating_cleaned.csv')","metadata":{"execution":{"iopub.status.busy":"2023-02-27T09:52:15.257763Z","iopub.execute_input":"2023-02-27T09:52:15.258173Z","iopub.status.idle":"2023-02-27T09:52:15.570593Z","shell.execute_reply.started":"2023-02-27T09:52:15.258140Z","shell.execute_reply":"2023-02-27T09:52:15.568717Z"},"trusted":true},"execution_count":203,"outputs":[]},{"cell_type":"markdown","source":"<h1 style=\"font-family:monospace; margin-left: 25px\">5. Split dataset into training and test set</h1>","metadata":{}},{"cell_type":"code","source":"X = dating.drop('match', axis = 1)\ny = dating['match'].astype('int')","metadata":{"execution":{"iopub.status.busy":"2023-02-27T09:52:15.572517Z","iopub.execute_input":"2023-02-27T09:52:15.573049Z","iopub.status.idle":"2023-02-27T09:52:15.584714Z","shell.execute_reply.started":"2023-02-27T09:52:15.573002Z","shell.execute_reply":"2023-02-27T09:52:15.582850Z"},"trusted":true},"execution_count":204,"outputs":[]},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 33 )","metadata":{"execution":{"iopub.status.busy":"2023-02-27T09:52:15.587410Z","iopub.execute_input":"2023-02-27T09:52:15.588011Z","iopub.status.idle":"2023-02-27T09:52:15.602982Z","shell.execute_reply.started":"2023-02-27T09:52:15.587958Z","shell.execute_reply":"2023-02-27T09:52:15.601395Z"},"trusted":true},"execution_count":205,"outputs":[]},{"cell_type":"markdown","source":"<h1 style=\"font-family:monospace\">6. Imputing, scaling and encoding</h1>\n<h2 style=\"font-family:monospace; margin-left: 25px\">6.1 Numeric variables</h2>\n<p style = \"font-family:georgia, serif; font-size:17px\">Numeric variables will be imputed by filling missing values with the median value and standardized using the standard scaler.</p>","metadata":{}},{"cell_type":"code","source":"# Instantiate the numeric imputer and scaler\nnum_imp = SimpleImputer(strategy = 'median')\nscaler = StandardScaler()","metadata":{"execution":{"iopub.status.busy":"2023-02-27T09:52:15.608644Z","iopub.execute_input":"2023-02-27T09:52:15.609140Z","iopub.status.idle":"2023-02-27T09:52:15.614527Z","shell.execute_reply.started":"2023-02-27T09:52:15.609102Z","shell.execute_reply":"2023-02-27T09:52:15.613299Z"},"trusted":true},"execution_count":206,"outputs":[]},{"cell_type":"code","source":"# Impute the training set\nX_train_imp = num_imp.fit_transform(X_train[columns_numeric])\n\n# Scale the training set\nX_train_imp_scaled = scaler.fit_transform(X_train_imp)\n\n# Convert the training set to a dataframe\nX_train_num_final = pd.DataFrame(X_train_imp_scaled, columns = columns_numeric)","metadata":{"execution":{"iopub.status.busy":"2023-02-27T09:52:15.616317Z","iopub.execute_input":"2023-02-27T09:52:15.617070Z","iopub.status.idle":"2023-02-27T09:52:15.683568Z","shell.execute_reply.started":"2023-02-27T09:52:15.617024Z","shell.execute_reply":"2023-02-27T09:52:15.682045Z"},"trusted":true},"execution_count":207,"outputs":[]},{"cell_type":"code","source":"# Impute the test set\nX_test_imp = num_imp.fit_transform(X_test[columns_numeric])\n\n# Scale the test set\nX_test_imp_scaled = scaler.fit_transform(X_test_imp)\n\n# Convert the test set to a dataframe\nX_test_num_final = pd.DataFrame(X_test_imp_scaled, columns = columns_numeric)","metadata":{"execution":{"iopub.status.busy":"2023-02-27T09:52:15.685285Z","iopub.execute_input":"2023-02-27T09:52:15.685689Z","iopub.status.idle":"2023-02-27T09:52:15.712860Z","shell.execute_reply.started":"2023-02-27T09:52:15.685654Z","shell.execute_reply":"2023-02-27T09:52:15.711114Z"},"trusted":true},"execution_count":208,"outputs":[]},{"cell_type":"markdown","source":"<h2 style=\"font-family:monospace; margin-left: 25px\">6.2 Categorical variables</h2>\n<p style = \"font-family:georgia, serif; font-size:17px\">Categorical variables will be imputed by filling missing values with the value \"Unknown\". The variables will then be encoded into numeric values using the dictvectorizer.</p>","metadata":{}},{"cell_type":"code","source":"# Instantiate the categorical imputer and the dictvectorizer\ncat_imp = SimpleImputer(missing_values = '?', fill_value = 'Unknown', strategy = 'constant')\nvectorizer = DictVectorizer(sparse = False)","metadata":{"execution":{"iopub.status.busy":"2023-02-27T09:52:15.715428Z","iopub.execute_input":"2023-02-27T09:52:15.716095Z","iopub.status.idle":"2023-02-27T09:52:15.723697Z","shell.execute_reply.started":"2023-02-27T09:52:15.716014Z","shell.execute_reply":"2023-02-27T09:52:15.722099Z"},"trusted":true},"execution_count":209,"outputs":[]},{"cell_type":"code","source":"# Impute the training set\nX_train_imp = cat_imp.fit_transform(X_train[columns_category])\n\n# Convert to dataframe\nX_train_imp_df = pd.DataFrame(X_train_imp, columns = columns_category)\n\n# Encode the training set \nX_train_cat_vect = vectorizer.fit_transform(X_train_imp_df[columns_category].to_dict('records'))\n\n# Convert to dataframe\nX_train_cat_final = pd.DataFrame(X_train_cat_vect, columns = vectorizer.get_feature_names_out())","metadata":{"execution":{"iopub.status.busy":"2023-02-27T09:52:15.725246Z","iopub.execute_input":"2023-02-27T09:52:15.725642Z","iopub.status.idle":"2023-02-27T09:52:15.813839Z","shell.execute_reply.started":"2023-02-27T09:52:15.725607Z","shell.execute_reply":"2023-02-27T09:52:15.812802Z"},"trusted":true},"execution_count":210,"outputs":[]},{"cell_type":"code","source":"# Impute the test set\nX_test_imp = cat_imp.fit_transform(X_test[columns_category])\n\n# Convert to dataframe\nX_test_imp_df = pd.DataFrame(X_test_imp, columns = columns_category)\n\n# Encode the test set \nX_test_cat_vect = vectorizer.fit_transform(X_test_imp_df[columns_category].to_dict('records'))\n\n# Convert to dataframe\nX_test_cat_final = pd.DataFrame(X_test_cat_vect, columns = vectorizer.get_feature_names_out())","metadata":{"execution":{"iopub.status.busy":"2023-02-27T09:52:15.814889Z","iopub.execute_input":"2023-02-27T09:52:15.815224Z","iopub.status.idle":"2023-02-27T09:52:15.854885Z","shell.execute_reply.started":"2023-02-27T09:52:15.815196Z","shell.execute_reply":"2023-02-27T09:52:15.852599Z"},"trusted":true},"execution_count":211,"outputs":[]},{"cell_type":"markdown","source":"<h2 style=\"font-family:monospace; margin-left: 25px\">6.3 Join numeric and categorical variables</h2>\n<p style = \"font-family:georgia, serif; font-size:17px\">The transformed numeric and categorical variables are joined together to form the training set and test set. The transformations and one hot encoding creates datasets with 70 features.</p>","metadata":{"execution":{"iopub.status.busy":"2023-02-22T13:59:53.484351Z","iopub.status.idle":"2023-02-22T13:59:53.485471Z","shell.execute_reply.started":"2023-02-22T13:59:53.485235Z","shell.execute_reply":"2023-02-22T13:59:53.485259Z"}}},{"cell_type":"code","source":"# Join numeric and categorical variables to create training set\nX_train = pd.concat([X_train_num_final,X_train_cat_final], axis = 1)\n\n# Join numeric and categorical variables to create test set\nX_test = pd.concat([X_test_num_final,X_test_cat_final], axis = 1)\n\nprint('Training set shape is',X_train.shape, 'and test shape shape is',X_test.shape)","metadata":{"execution":{"iopub.status.busy":"2023-02-27T09:52:15.856739Z","iopub.execute_input":"2023-02-27T09:52:15.857601Z","iopub.status.idle":"2023-02-27T09:52:15.868996Z","shell.execute_reply.started":"2023-02-27T09:52:15.857562Z","shell.execute_reply":"2023-02-27T09:52:15.867530Z"},"trusted":true},"execution_count":212,"outputs":[{"name":"stdout","text":"Training set shape is (6283, 70) and test shape shape is (2095, 70)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"<h1 style=\"font-family:monospace\">7. Model evaluation before dimension reduction</h1>\n<p style = \"font-family:georgia, serif; font-size:17px\">We train and evaluate our models before we begin dimension reduction to find the accuracy when we use all the features. We will use the xgboost classifier for our evaluation since it has the highest accuracy of 0.875. This will therefore be the base value with which we will compare the accuracy of our model after dimension reduction</p>","metadata":{}},{"cell_type":"code","source":"# We instantiate different models to test their accuracy\nlogreg = LogisticRegression(max_iter = 10000)\nsvc = SVC()\nknn = KNeighborsClassifier()\nrf = RandomForestClassifier()\nxg_cl = xgb.XGBClassifier()\n\nclassifiers = [('logreg',logreg),('svc',svc),('knn',knn),('random forest',rf),('xgboost',xg_cl)]\n\n# We fit the different models and compute the accuracy\nfor clf_name, model in classifiers:\n    model.fit(X_train, y_train)\n    y_pred = model.predict(X_test)\n    accuracy = (np.sum(y_pred == y_test))/(len(y_pred))\n    print(clf_name, accuracy)\n    ","metadata":{"execution":{"iopub.status.busy":"2023-02-27T09:52:15.870899Z","iopub.execute_input":"2023-02-27T09:52:15.871699Z","iopub.status.idle":"2023-02-27T09:52:20.050208Z","shell.execute_reply.started":"2023-02-27T09:52:15.871662Z","shell.execute_reply":"2023-02-27T09:52:20.047624Z"},"trusted":true},"execution_count":213,"outputs":[{"name":"stdout","text":"logreg 0.8606205250596659\nsvc 0.8725536992840095\nknn 0.837708830548926\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_27/3214789429.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# We fit the different models and compute the accuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mclf_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mclassifiers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    465\u001b[0m                     \u001b[0mn_samples_bootstrap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_samples_bootstrap\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    466\u001b[0m                 )\n\u001b[0;32m--> 467\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrees\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    468\u001b[0m             )\n\u001b[1;32m    469\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1042\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1043\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1044\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1045\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1046\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    857\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 859\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    860\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    775\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    776\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 777\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    778\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 263\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 263\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/utils/fixes.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    214\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36m_parallel_build_trees\u001b[0;34m(tree, forest, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap)\u001b[0m\n\u001b[1;32m    183\u001b[0m             \u001b[0mcurr_sample_weight\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0mcompute_sample_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"balanced\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m         \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcurr_sample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m         \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    940\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    941\u001b[0m             \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 942\u001b[0;31m             \u001b[0mX_idx_sorted\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_idx_sorted\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    943\u001b[0m         )\n\u001b[1;32m    944\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    418\u001b[0m             )\n\u001b[1;32m    419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 420\u001b[0;31m         \u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mis_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"markdown","source":"<h1 style=\"font-family:monospace\">8. Dimension reduction</h1>\n<h2 style=\"font-family:monospace; margin-left: 25px\">8.1 Feature selection with Random forests</h2>\n<p style = \"font-family:georgia, serif; font-size:17px\">Random forest classifiers have a feature importances attribute that shows the contribution of each feature to the model. </p>","metadata":{"execution":{"iopub.status.busy":"2023-02-22T18:17:55.889747Z","iopub.status.idle":"2023-02-22T18:17:55.890216Z","shell.execute_reply.started":"2023-02-22T18:17:55.889980Z","shell.execute_reply":"2023-02-22T18:17:55.890000Z"}}},{"cell_type":"code","source":"rf = RandomForestClassifier()\n\n# Fit the classifier\nrf.fit(X_train, y_train)\n\n# Retrieve the feature importances\nrf_importance = pd.Series(rf.feature_importances_, index = rf.feature_names_in_)\nrf_importance = rf_importance.sort_values(ascending = False)\nrf_importance.head()","metadata":{"execution":{"iopub.status.busy":"2023-02-27T09:52:20.051130Z","iopub.status.idle":"2023-02-27T09:52:20.051592Z","shell.execute_reply.started":"2023-02-27T09:52:20.051378Z","shell.execute_reply":"2023-02-27T09:52:20.051400Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style = \"font-family:georgia, serif; font-size:17px\">\n    \nThe top most important features according to the random forest classifier are:\n1. Rating by partner (about me) on attractiveness\n2. Whether they like their partner\n3. Rating by partner (about me) on shared interest\n4. Rating by partner (about me) at night of event on being funny\n5. Rating on your partner being funny\n\nThe least important feature is the race of the person or of their parner.\n    \n</div>","metadata":{}},{"cell_type":"code","source":"# Visualizing the feature importances\nfig = plt.figure(figsize = (10,12))\nrf_importance.plot(kind = 'barh', width =0.8)\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-02-27T09:52:20.052744Z","iopub.status.idle":"2023-02-27T09:52:20.053356Z","shell.execute_reply.started":"2023-02-27T09:52:20.052996Z","shell.execute_reply":"2023-02-27T09:52:20.053024Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<p style = \"font-family:georgia, serif; font-size:17px\">The feature importance values of random forests are in percentage. Therefore, we can try and select features with a contribution of more than 1% and see if removing the features reduces noise, thus improving our model accuracy.</p>","metadata":{}},{"cell_type":"code","source":"# Selecting features \ntop_features = rf_importance[rf_importance>0.01].index\n\nxg_cl = xgb.XGBClassifier()\n\n# Fit the model\nxg_cl.fit(X_train[top_features], y_train)\n\n# Make predictions\ny_pred = xg_cl.predict(X_test[top_features])\naccuracy = (np.sum(y_pred == y_test))/(len(y_pred))\nprint(f'Dropping features from {len(rf_importance)} to {len(top_features)} give an accuracy of {accuracy}')","metadata":{"execution":{"iopub.status.busy":"2023-02-27T09:52:20.054582Z","iopub.status.idle":"2023-02-27T09:52:20.055053Z","shell.execute_reply.started":"2023-02-27T09:52:20.054813Z","shell.execute_reply":"2023-02-27T09:52:20.054833Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h2 style=\"font-family:monospace; margin-left: 25px\">8.2 Feature selection with xgboost</h2>\n\n<div style = \"font-family:georgia, serif; font-size:17px\">\n    \nXgboost is used in feature selection by outputting feature importance values from a trained model. To leverage the performance and efficiency of the algorithm, the dataset is converted to a DMatrix format which is used for training. \nThe top most important features according to the xgboost classifier are:\n1. Rating by partner (about me) on attractiveness\n2. Rating of how you think your partner likes you?\n3. Rating by partner (about me) on being funny\n4. Rating by partner (about me) on shared interest\n5. How many matches do you expect to get?\n\nXgboost has the .plot_importance() method that is used to visualize the importance values of all features in a plot.\n</div>","metadata":{"execution":{"iopub.status.busy":"2023-02-22T19:15:22.259345Z","iopub.execute_input":"2023-02-22T19:15:22.259770Z","iopub.status.idle":"2023-02-22T19:15:22.269404Z","shell.execute_reply.started":"2023-02-22T19:15:22.259735Z","shell.execute_reply":"2023-02-22T19:15:22.267899Z"}}},{"cell_type":"code","source":"# Convert the data to dmatrix\ndating_matrix = xgb.DMatrix(data = X_train, label = y_train)\nparams = {'objective':'binary:logistic'}\n\n# Train data using dmatrix format\nxgb_clf = xgb.train(dtrain = dating_matrix, params = params, num_boost_round = 10)\n\n# Plot the feature importances\nfig, ax  = plt.subplots(figsize = (13,16))\nxgb.plot_importance(xgb_clf, ax = ax)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-02-27T09:52:20.057038Z","iopub.status.idle":"2023-02-27T09:52:20.057491Z","shell.execute_reply.started":"2023-02-27T09:52:20.057279Z","shell.execute_reply":"2023-02-27T09:52:20.057299Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<p style = \"font-family:georgia, serif; font-size:17px\">In xgboost, the scores of each feature can be retrieved using the .get_score() method</p>","metadata":{}},{"cell_type":"code","source":"xgb_features = pd.DataFrame(xgb_clf.get_score(), index = ['score']).T\nxgb_features['score'].sort_values(ascending=False).head(8)","metadata":{"execution":{"iopub.status.busy":"2023-02-27T09:52:20.059624Z","iopub.status.idle":"2023-02-27T09:52:20.060150Z","shell.execute_reply.started":"2023-02-27T09:52:20.059890Z","shell.execute_reply":"2023-02-27T09:52:20.059912Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<p style = \"font-family:georgia, serif; font-size:17px\">We will evaluate the accuracy of the model with features with a score greater than 3. This selects 47 features which does not greatly affect our accuracy.</p>","metadata":{}},{"cell_type":"code","source":"xgb_cl = xgb.XGBClassifier()\n\n# Selecting features\nxgb_top_features = xgb_features[xgb_features['score'] > 3].index\n\n# Fit and predict\nxgb_cl.fit(X_train[xgb_top_features],y_train)\ny_pred = xgb_cl.predict(X_test[xgb_top_features])\naccuracy = (np.sum(y_pred == y_test))/(len(y_pred))\nprint(f'Dropping features from 70 to {len(xgb_top_features)} results in an accuracy of {accuracy}')","metadata":{"execution":{"iopub.status.busy":"2023-02-27T09:52:20.061886Z","iopub.status.idle":"2023-02-27T09:52:20.062383Z","shell.execute_reply.started":"2023-02-27T09:52:20.062170Z","shell.execute_reply":"2023-02-27T09:52:20.062191Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h2 style=\"font-family:monospace; margin-left: 25px\">8.3 Dimension reduction with Recursive Feature Elimination - RFE</h2>\n\n<div style = \"font-family:georgia, serif; font-size:17px\">\n    \nRFE is feature selection algorithm that produces feature importances or feature coeffients when a model is passed to it. It fits the model and drops the weakest features, and repeats the process until the specified number of features is attained. \n\nUsing xgboost classifier, we test the accuracy of different number of features As seen below, the accuracy of a model with 70 features isn't very different with a model fitted with 40 features. In fact, reducing features from 30 to 15 has an insignificant impact on the model's accuracy. \n\nIn essence, if you are more concerned with what features play an important role in your prediction, the automatic selection of features by the recursive feature elimination method is very effective. In this circumstance, it's a tradeoff between dimensionality and accuracy. \n\n</div>","metadata":{}},{"cell_type":"code","source":"from sklearn.feature_selection import RFE\n\nxgb_cl = xgb.XGBClassifier()\n\nfor features in list(range(70,1,-5)):\n    # Instantiate and fit the RFE\n    rfe = RFE(estimator = xgb_cl, n_features_to_select = features)\n    rfe.fit(X_train,y_train)\n    \n    # Make predictions\n    y_pred = rfe.predict(X_test)\n    accuracy = (np.sum(y_pred == y_test))/(len(y_pred))\n    print(f'The accuracy of {features} features is {accuracy}')","metadata":{"execution":{"iopub.status.busy":"2023-02-27T09:52:20.064207Z","iopub.status.idle":"2023-02-27T09:52:20.064653Z","shell.execute_reply.started":"2023-02-27T09:52:20.064449Z","shell.execute_reply":"2023-02-27T09:52:20.064470Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h3 style=\"font-family:monospace; margin-left: 25px\">8.3.1 Selecting the features</h3>\n<p style = \"font-family:georgia, serif; font-size:17px\">Suppose we want a balance between dimensionality of the dataset and the accuracy, we can select 15 features whose accuracy is 0.867. The .support_ attribute is used to give a mask with True and False values for features selected and those not selected respectively.</p>","metadata":{}},{"cell_type":"code","source":"xgb_cl = xgb.XGBClassifier()\n\n# Instatiate RFE with 15 features\nrfe = RFE(estimator = xgb.XGBClassifier(), n_features_to_select = 15)\n\n# Fit and predict\nrfe.fit(X_train,y_train)\ny_pred = rfe.predict(X_test)\naccuracy = (np.sum(y_pred == y_test))/(len(y_pred))\nprint(f'Model accuracy is {accuracy}')\n\n# Select a mask with features selected\nmask = rfe.support_\nxgb_top_15_features = X_train.columns[mask].tolist()\nprint(f'\\nTop 15 features in the xgb classifier are:\\n{xgb_top_15_features}')","metadata":{"execution":{"iopub.status.busy":"2023-02-27T09:52:20.065783Z","iopub.status.idle":"2023-02-27T09:52:20.066202Z","shell.execute_reply.started":"2023-02-27T09:52:20.066010Z","shell.execute_reply":"2023-02-27T09:52:20.066029Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h3 style=\"font-family:monospace; margin-left: 25px\">8.3.2 Combining features from different models</h3>\n<p style = \"font-family:georgia, serif; font-size:17px\">You can use different models and choose features with selected by all the models, and then use these features for prediction. We will select the top 30 features in three models and select common features</p>\n\n<h4 style=\"font-family:monospace; margin-left: 25px\">Selecting random forest features</h4>","metadata":{"execution":{"iopub.status.busy":"2023-02-23T09:04:12.152840Z","iopub.execute_input":"2023-02-23T09:04:12.153260Z","iopub.status.idle":"2023-02-23T09:04:12.161928Z","shell.execute_reply.started":"2023-02-23T09:04:12.153226Z","shell.execute_reply":"2023-02-23T09:04:12.160658Z"}}},{"cell_type":"code","source":"rf = RandomForestClassifier()\n\nrfe = RFE(estimator = rf, n_features_to_select = 30)\nrfe.fit(X_train,y_train)\ny_pred = rfe.predict(X_test)\naccuracy = (np.sum(y_pred == y_test))/(len(y_pred))\nprint(f'Model accuracy is {accuracy}')\n\nmask_rfe = rfe.support_","metadata":{"execution":{"iopub.status.busy":"2023-02-27T09:52:20.068069Z","iopub.status.idle":"2023-02-27T09:52:20.068498Z","shell.execute_reply.started":"2023-02-27T09:52:20.068281Z","shell.execute_reply":"2023-02-27T09:52:20.068301Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h4 style=\"font-family:monospace; margin-left: 25px\">Selecting logistic Regression features</h4>","metadata":{}},{"cell_type":"code","source":"logreg = LogisticRegression(max_iter =100000)\n\nrfe = RFE(estimator = logreg, n_features_to_select = 30)\nrfe.fit(X_train,y_train)\ny_pred = rfe.predict(X_test)\naccuracy = (np.sum(y_pred == y_test))/(len(y_pred))\nprint(f'Model accuracy is {accuracy}')\n\nmask_log = rfe.support_","metadata":{"execution":{"iopub.status.busy":"2023-02-27T09:52:20.069823Z","iopub.status.idle":"2023-02-27T09:52:20.070263Z","shell.execute_reply.started":"2023-02-27T09:52:20.070060Z","shell.execute_reply":"2023-02-27T09:52:20.070080Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h4 style=\"font-family:monospace; margin-left: 25px\">Selecting xgboost features</h4>","metadata":{}},{"cell_type":"code","source":"xgb_cl = xgb.XGBClassifier()\n\nrfe = RFE(estimator = xgb_cl, n_features_to_select = 30)\nrfe.fit(X_train,y_train)\ny_pred = rfe.predict(X_test)\naccuracy = (np.sum(y_pred == y_test))/(len(y_pred))\nprint(f'Model accuracy is {accuracy}')\n\nmask_xgb = rfe.support_","metadata":{"execution":{"iopub.status.busy":"2023-02-27T09:52:20.071590Z","iopub.status.idle":"2023-02-27T09:52:20.072026Z","shell.execute_reply.started":"2023-02-27T09:52:20.071813Z","shell.execute_reply":"2023-02-27T09:52:20.071832Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h3 style=\"font-family:monospace; margin-left: 25px\">8.3.3 Evaluating features selected by the three classifiers</h3>\n<p style = \"font-family:georgia, serif; font-size:17px\">After selecting 30 features in all our models, we will combine them to select features chosen by all the models. We will use these features for our prediction. A total of 11 features were present in all the models.</p>","metadata":{}},{"cell_type":"code","source":"# Find sum of mask to identify common features \nmask_all_models = np.sum([mask_rfe, mask_log,mask_xgb], axis=0)\n\n# Select features selected by all the three models\nmask = mask_all_models == 3\nmost_important_features = X_train.columns[mask]\n\nprint(most_important_features.shape)\nprint()\nprint(most_important_features)","metadata":{"execution":{"iopub.status.busy":"2023-02-27T09:52:20.073367Z","iopub.status.idle":"2023-02-27T09:52:20.073763Z","shell.execute_reply.started":"2023-02-27T09:52:20.073564Z","shell.execute_reply":"2023-02-27T09:52:20.073583Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<p style = \"font-family:georgia, serif; font-size:17px\">When the 11 features selected by the three models are evaluated, they give an accuracy of 0.863 with xgboost, a value not very far from 0.875 when using 70 features.</p>","metadata":{}},{"cell_type":"code","source":"xg_cl = xgb.XGBClassifier()\n\nxg_cl.fit(X_train[most_important_features], y_train)\ny_pred = xg_cl.predict(X_test[most_important_features])\naccuracy = (np.sum(y_pred == y_test))/(len(y_pred))\nprint(f'Accuracy of 11 features selected by all models is {accuracy}')    ","metadata":{"execution":{"iopub.status.busy":"2023-02-27T09:52:20.075589Z","iopub.status.idle":"2023-02-27T09:52:20.076289Z","shell.execute_reply.started":"2023-02-27T09:52:20.076082Z","shell.execute_reply":"2023-02-27T09:52:20.076105Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h2 style=\"font-family:monospace; margin-left: 25px\">8.4 Dimension reduction with PCA</h2>\n<p style = \"font-family:georgia, serif; font-size:17px\">PCA is another dimension-reduction technique. It has the explained_variance_ratio_ attribute that provides the variance of each feature. </p>","metadata":{"execution":{"iopub.status.busy":"2023-02-23T09:52:26.855261Z","iopub.execute_input":"2023-02-23T09:52:26.855897Z","iopub.status.idle":"2023-02-23T09:52:26.863075Z","shell.execute_reply.started":"2023-02-23T09:52:26.855860Z","shell.execute_reply":"2023-02-23T09:52:26.861379Z"}}},{"cell_type":"code","source":"pca = PCA()\npca.fit(X_train, y_train)\nvariance = pca.explained_variance_ratio_\nvariance","metadata":{"execution":{"iopub.status.busy":"2023-02-27T09:52:20.077749Z","iopub.status.idle":"2023-02-27T09:52:20.078199Z","shell.execute_reply.started":"2023-02-27T09:52:20.077992Z","shell.execute_reply":"2023-02-27T09:52:20.078012Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<p style = \"font-family:georgia, serif; font-size:17px\">A plot of explained variance ratio is a good indicator of the ideal number of n_components to be used in PCA. The number of components is picked from the elbow where there is an abrupt shift in explained variance. In this case, it is 11.</p>","metadata":{}},{"cell_type":"code","source":"fig = plt.figure(figsize = (10,6))\nsns.lineplot(variance)\nplt.grid(True)\nplt.xlabel('Number')\nplt.ylabel('Explained variance ratio')\nplt.title('A plot of explained variance')\nplt.xticks(np.arange(0,80,10), np.arange(1,81,10))\nplt.annotate('Elbow',xy =[9, 0.022], xytext = [31, 0.04], arrowprops=dict(facecolor='grey', shrink=0.05))\nplt.tight_layout()\nfig.savefig('/kaggle/working/PCA.png',)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-02-27T09:52:20.080352Z","iopub.status.idle":"2023-02-27T09:52:20.080744Z","shell.execute_reply.started":"2023-02-27T09:52:20.080554Z","shell.execute_reply":"2023-02-27T09:52:20.080573Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<p style = \"font-family:georgia, serif; font-size:17px\">Using the number of components from the elbow, we fit_transform the train dataset and tranform the test set. Using the xgb classifier after reducing the dimensions of data from 70 to 11 features results in an accuracy of 0.85, a slight drop from 0.87 when using 70 features.</p>","metadata":{}},{"cell_type":"code","source":"# Instantiate PCA with 11 components\npca = PCA(n_components = 11)\n\nxgb_cl = xgb.XGBClassifier()\n\n# Fit and transform the training set\nX_train_transformed = pca.fit_transform(X_train)\n\n# Transform the test set\nX_test_tranformed = pca.transform(X_test)\n\n# Fit and predict with the transformed datasets\nxgb_cl.fit(X_train_transformed,y_train)\ny_pred = xgb_cl.predict(X_test_tranformed)\naccuracy = (np.sum(y_pred == y_test))/(len(y_pred))\nprint(accuracy)","metadata":{"execution":{"iopub.status.busy":"2023-02-27T09:52:20.082663Z","iopub.status.idle":"2023-02-27T09:52:20.083121Z","shell.execute_reply.started":"2023-02-27T09:52:20.082889Z","shell.execute_reply":"2023-02-27T09:52:20.082908Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}